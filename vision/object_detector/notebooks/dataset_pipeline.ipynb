{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF2AaAk1IEaV"
      },
      "source": [
        "# Object detector dataset generator\n",
        "\n",
        "With this notebook you'll be able to artificially generate and automatically label\n",
        "a dataset for detecting objects. You can bring your own images or test it by fetching images from Kaggle hub.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCK-uHgydy0J"
      },
      "source": [
        "If running on colab, install dependencies:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "8BwpM1sG-6vw",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "a1b4ed0b-4d79-485b-ec3a-7ddc35d8122c"
      },
      "outputs": [],
      "source": [
        "!pip install numpy opencv-python pillow pycocotools pyyaml torch ultralytics matplotlib imutils argparse groundingdino-py segment-anything"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ou32WeHhVHR"
      },
      "source": [
        "If you want to mount your google drive for training with checkpoints in colab and saving your progress run the following cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRE8LH5WIGhh"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/sample_data\n",
        "!rm -rf /content/.config\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content', force_remount=True)\n",
        "workdir = \"/content/MyDrive/RoBorregos/vision/dataset_generator/\"\n",
        "os.makedirs(workdir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ0HDRBHs7c_",
        "outputId": "fafff6e6-d4df-4a94-be8c-75cae1567f4c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw61UICTMCIk"
      },
      "source": [
        "If not mounting a drive run the next cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZoFECOyL7zi"
      },
      "outputs": [],
      "source": [
        "workdir = \"/home/roborregos/visao/home-pipelines/vision/object_detector/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFGYuTSq-c5M",
        "outputId": "fce74b3a-c087-41da-881b-ac1a94745864"
      },
      "outputs": [],
      "source": [
        "from groundingdino.util.vl_utils import create_positive_map_from_span\n",
        "from groundingdino.util.utils import clean_state_dict, get_phrases_from_posmap\n",
        "from groundingdino.util.slconfig import SLConfig\n",
        "from groundingdino.util.inference import load_model, predict\n",
        "from groundingdino.util import box_ops\n",
        "from groundingdino.models import build_model\n",
        "import groundingdino.datasets.transforms as T\n",
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "import argparse\n",
        "import imutils\n",
        "import time\n",
        "import ultralytics\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import csv\n",
        "import yaml\n",
        "from pycocotools import mask\n",
        "from PIL import Image, ImageDraw, ImageEnhance, ImageFilter, ImageFont, UnidentifiedImageError\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "os.chdir(\"/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5oN4FDoBSwW"
      },
      "source": [
        "# Attention!\n",
        "\n",
        "If you have specific pictures, place the folders in ./images and skip the next two blocks of code which download a default dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kbz7bnpTIx6a"
      },
      "outputs": [],
      "source": [
        "!pip install kagglehub\n",
        "import kagglehub\n",
        "\n",
        "dataset_path = kagglehub.dataset_download(\"bhavikjikadara/dog-and-cat-classification-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V38GLZoAAnGw"
      },
      "outputs": [],
      "source": [
        "!cp -r {dataset_path}/PetImages {workdir}\n",
        "!mv {workdir}/PetImages {workdir}/images\n",
        "\n",
        "def clean_and_trim_dataset(folder):\n",
        "    total_removed = 0\n",
        "\n",
        "    for category in [\"Cat\", \"Dog\"]:\n",
        "        path = os.path.join(folder, category)\n",
        "        valid_images = []\n",
        "\n",
        "        # Step 1: Remove corrupt images\n",
        "        for img_name in os.listdir(path):\n",
        "            img_path = os.path.join(path, img_name)\n",
        "            try:\n",
        "                with Image.open(img_path) as img:\n",
        "                    img.verify()\n",
        "                valid_images.append(img_path)\n",
        "            except (UnidentifiedImageError, OSError):\n",
        "                os.remove(img_path)\n",
        "                total_removed += 1\n",
        "\n",
        "        print(f\"Removed {total_removed} corrupt images from {category}\")\n",
        "\n",
        "        # Step 2: Remove part of the remaining valid images\n",
        "        to_delete = random.sample(valid_images, len(valid_images) * 99 // 100)\n",
        "        for img_path in to_delete:\n",
        "            os.remove(img_path)\n",
        "\n",
        "        print(f\"Removed {len(to_delete)} images from {category} to reduce dataset size\")\n",
        "\n",
        "clean_and_trim_dataset(workdir + \"images\")\n",
        "\n",
        "def count_files_in_dir(directory):\n",
        "    # List all files (images) in the directory and count them\n",
        "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
        "    return len(files)\n",
        "\n",
        "# Example usage for \"Cat\" and \"Dog\" folders\n",
        "cat_folder = workdir + \"images/Cat\"\n",
        "dog_folder = workdir + \"images/Dog\"\n",
        "\n",
        "print(f\"Number of cat images: {count_files_in_dir(cat_folder)}\")\n",
        "print(f\"Number of dog images: {count_files_in_dir(dog_folder)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0XKknj0p4cY"
      },
      "source": [
        "## Crop images to 1:1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxhO1b5bp4cY"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, UnidentifiedImageError, ImageOps\n",
        "import os\n",
        "\n",
        "base_path = workdir + \"images\"\n",
        "\n",
        "for class_dir in os.listdir(base_path):\n",
        "    class_path = os.path.join(base_path, class_dir)\n",
        "\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "    print(class_path)\n",
        "    for filename in os.listdir(class_path):\n",
        "        file_path = os.path.join(class_path, filename)\n",
        "\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                # Apply EXIF orientation\n",
        "                img = ImageOps.exif_transpose(img)\n",
        "\n",
        "                width, height = img.size\n",
        "                min_dim = min(width, height)\n",
        "\n",
        "                left = (width - min_dim) // 2\n",
        "                top = (height - min_dim) // 2\n",
        "                right = left + min_dim\n",
        "                bottom = top + min_dim\n",
        "\n",
        "                img_cropped = img.crop((left, top, right, bottom))\n",
        "                img_cropped.save(file_path)\n",
        "        except (UnidentifiedImageError, OSError) as e:\n",
        "            print(f\"Removing corrupt file: {file_path}\")\n",
        "            os.remove(file_path)\n",
        "\n",
        "os.chdir(workdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBqfbPuhp4cY"
      },
      "source": [
        "## Resize images\n",
        "\n",
        "If tight on time, consider resizing down the images for faster segmentation and other processes, if not skip this step for better dataset quality (considering the images are high resolution).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_q0rbC8z1np"
      },
      "outputs": [],
      "source": [
        "base_path = workdir + \"images\"\n",
        "size = 1280\n",
        "\n",
        "for class_dir in os.listdir(base_path):\n",
        "    class_path = os.path.join(base_path, class_dir)\n",
        "\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "    print(class_path)\n",
        "    for filename in os.listdir(class_path):\n",
        "        file_path = os.path.join(class_path, filename)\n",
        "\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                img = img.resize((size, size))\n",
        "                img.save(file_path)\n",
        "        except (UnidentifiedImageError, OSError) as e:\n",
        "            print(f\"Removing corrupt file: {file_path}\")\n",
        "            os.remove(file_path)  # delete corrupt image\n",
        "\n",
        "os.chdir(workdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFg8rFwzp4cY"
      },
      "source": [
        "## Rotate images\n",
        "\n",
        "If needed rotate the image an amount of degrees.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QhgVv4wp4cY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "angle = 90\n",
        "\n",
        "\n",
        "def rotate_images_in_directory(directory):\n",
        "    count = 0\n",
        "    for filename in os.listdir(directory):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        if os.path.isfile(filepath):\n",
        "            try:\n",
        "                with Image.open(filepath) as img:\n",
        "                    rotated = img.rotate(angle, expand=True)\n",
        "                    rotated.save(filepath)\n",
        "                    count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to process {filename}: {e}\")\n",
        "    print(f\"Rotated {count} images in {directory}\")\n",
        "\n",
        "\n",
        "def rotate_all_subdirs(base_directory):\n",
        "    for subdir in os.listdir(base_directory):\n",
        "        subdir_path = os.path.join(base_directory, subdir)\n",
        "        if os.path.isdir(subdir_path):\n",
        "            rotate_images_in_directory(subdir_path)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "# rotate_all_subdirs(os.path.join(workdir, \"processed/Apple\"))\n",
        "rotate_images_in_directory(workdir + \"processed/Soap\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2Nl0FnupalH"
      },
      "source": [
        "## Download models\n",
        "\n",
        "If you have already ran this and are using a volume/drive there is no need to run again.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldTlMrhBbZ1m",
        "outputId": "d3f1343a-7f2e-432c-ecf5-77b210daa587",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
        "!wget https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n",
        "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgHibh11p4cY"
      },
      "source": [
        "## Segment images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-G0iL0HJywT",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "SAVE_BB = False\n",
        "DEBUG = False\n",
        "\n",
        "# path to save results already processed and segmented images\n",
        "results_path = workdir + \"processed\"\n",
        "# change the path of the model config file\n",
        "config_file = workdir + \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
        "# change the path of the model\n",
        "checkpoint_path = workdir + \"groundingdino_swint_ogc.pth\"\n",
        "output_dir = results_path\n",
        "box_threshold = 0.3\n",
        "text_threshold = 0.25\n",
        "token_spans = None\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "sam_model = \"h\"\n",
        "\n",
        "# use sam model\n",
        "# wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "# wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth\n",
        "if sam_model == \"h\":\n",
        "    sam_checkpoint = workdir + \"sam_vit_h_4b8939.pth\"\n",
        "    model_type = \"vit_h\"\n",
        "else:\n",
        "    sam_checkpoint = workdir + \"sam_vit_l_0b3195.pth\"\n",
        "    model_type = \"vit_l\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using\", device)\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "predictor = SamPredictor(sam)\n",
        "\n",
        "images = []\n",
        "annotations = []\n",
        "categories = []\n",
        "\n",
        "img_id = 0\n",
        "anno_id = 0\n",
        "\n",
        "# Make a list of all the directories in the path\n",
        "base_path = workdir + \"images\"\n",
        "path_to_classes = [f.path for f in os.scandir(base_path) if f.is_dir()]\n",
        "\n",
        "\n",
        "def load_image(image_path):\n",
        "\n",
        "    image_pil = Image.open(image_path).convert(\"RGB\")  # load image\n",
        "\n",
        "    transform = T.Compose(\n",
        "        [\n",
        "            T.RandomResize([800], max_size=1333),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "    image, _ = transform(image_pil, None)  # 3, h, w\n",
        "    return image_pil, image\n",
        "\n",
        "\n",
        "def load_model(model_config_path, model_checkpoint_path, cpu_only=False):\n",
        "    args = SLConfig.fromfile(model_config_path)\n",
        "    args.device = device\n",
        "    model = build_model(args)\n",
        "    checkpoint = torch.load(model_checkpoint_path, map_location=\"cpu\")\n",
        "    load_res = model.load_state_dict(\n",
        "        clean_state_dict(checkpoint[\"model\"]), strict=False)\n",
        "    if DEBUG:\n",
        "        print(load_res)\n",
        "    _ = model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_grounding_output(model, image, caption, box_threshold, text_threshold=None, with_logits=True, cpu_only=False, token_spans=None):\n",
        "    assert text_threshold is not None or token_spans is not None, \"text_threshould and token_spans should not be None at the same time!\"\n",
        "    caption = caption.lower()\n",
        "    caption = caption.strip()\n",
        "    if not caption.endswith(\".\"):\n",
        "        caption = caption + \".\"\n",
        "    model = model.to(device)\n",
        "    image = image.to(device)\n",
        "    with torch.no_grad():\n",
        "        if DEBUG:\n",
        "            print(\"Running model...\")\n",
        "        outputs = model(image[None], captions=[caption])\n",
        "    logits = outputs[\"pred_logits\"].sigmoid()[0]  # (nq, 256)\n",
        "    boxes = outputs[\"pred_boxes\"][0]  # (nq, 4)\n",
        "\n",
        "    # filter output\n",
        "    if token_spans is None:\n",
        "        logits_filt = logits.cpu().clone()\n",
        "        boxes_filt = boxes.cpu().clone()\n",
        "        filt_mask = logits_filt.max(dim=1)[0] > box_threshold\n",
        "        logits_filt = logits_filt[filt_mask]  # num_filt, 256\n",
        "        boxes_filt = boxes_filt[filt_mask]  # num_filt, 4\n",
        "\n",
        "        # get phrase\n",
        "        tokenlizer = model.tokenizer\n",
        "        tokenized = tokenlizer(caption)\n",
        "        # build pred\n",
        "        pred_phrases = []\n",
        "        for logit, box in zip(logits_filt, boxes_filt):\n",
        "            pred_phrase = get_phrases_from_posmap(\n",
        "                logit > text_threshold, tokenized, tokenlizer)\n",
        "            if with_logits:\n",
        "                pred_phrases.append(\n",
        "                    pred_phrase + f\"({str(logit.max().item())[:4]})\")\n",
        "            else:\n",
        "                pred_phrases.append(pred_phrase)\n",
        "    else:\n",
        "        # given-phrase mode\n",
        "        positive_maps = create_positive_map_from_span(\n",
        "            model.tokenizer(text_prompt),\n",
        "            token_span=token_spans\n",
        "        ).to(image.device)  # n_phrase, 256\n",
        "\n",
        "        logits_for_phrases = positive_maps @ logits.T  # n_phrase, nq\n",
        "        all_logits = []\n",
        "        all_phrases = []\n",
        "        all_boxes = []\n",
        "        for (token_span, logit_phr) in zip(token_spans, logits_for_phrases):\n",
        "            # get phrase\n",
        "            phrase = ' '.join([caption[_s:_e] for (_s, _e) in token_span])\n",
        "            # get mask\n",
        "            filt_mask = logit_phr > box_threshold\n",
        "            # filt box\n",
        "            all_boxes.append(boxes[filt_mask])\n",
        "            # filt logits\n",
        "            all_logits.append(logit_phr[filt_mask])\n",
        "            if with_logits:\n",
        "                logit_phr_num = logit_phr[filt_mask]\n",
        "                all_phrases.extend(\n",
        "                    [phrase + f\"({str(logit.item())[:4]})\" for logit in logit_phr_num])\n",
        "            else:\n",
        "                all_phrases.extend([phrase for _ in range(len(filt_mask))])\n",
        "        boxes_filt = torch.cat(all_boxes, dim=0).cpu()\n",
        "        pred_phrases = all_phrases\n",
        "    return boxes_filt, pred_phrases\n",
        "\n",
        "\n",
        "def verify_or_create_dir(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    if DEBUG:\n",
        "        print(f\"Verified/created: {path}\")\n",
        "\n",
        "\n",
        "def count_all_files_in_dir(directory):\n",
        "    count = 0\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        count += len([f for f in files if os.path.isfile(os.path.join(root, f))])\n",
        "    return count\n",
        "\n",
        "\n",
        "# Get total number of images to process\n",
        "image_dir = workdir + \"images\"\n",
        "number_of_images = count_all_files_in_dir(image_dir)\n",
        "print(f\"Total image files: {number_of_images}\")\n",
        "\n",
        "# Check if results directory exists, else create it\n",
        "verify_or_create_dir(results_path)\n",
        "\n",
        "# Main loop\n",
        "i = 0\n",
        "for class_path in path_to_classes:\n",
        "    imgPaths = os.listdir(class_path)\n",
        "    if SAVE_BB:\n",
        "        class_name = os.path.basename(class_path)\n",
        "        verify_or_create_dir(f\"{results_path}/bbs/{class_name}\")\n",
        "\n",
        "    for imgPath in imgPaths:\n",
        "        if DEBUG:\n",
        "            print(f\"Processing image: {imgPath}\")\n",
        "        print(f\"%{i * 100 / number_of_images}\")\n",
        "        img = imutils.resize(cv2.imread(f\"{class_path}/{imgPath}\"))\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "    # ------------------------start grounding----------------------------------------------\n",
        "\n",
        "        # Image_path = args.image_path\n",
        "        cpu_only = False if torch.cuda.is_available() else True\n",
        "\n",
        "        # Load image\n",
        "        image_pil, image = load_image(f\"{class_path}/{imgPath}\")\n",
        "\n",
        "        # Load model\n",
        "        model = load_model(config_file, checkpoint_path, cpu_only=cpu_only)\n",
        "\n",
        "        # Set the text_threshold to None if token_spans is set.\n",
        "        if token_spans is not None:\n",
        "            text_threshold = None\n",
        "            print(\"Using token_spans. Set the text_threshold to None.\")\n",
        "\n",
        "        # Run model\n",
        "        text_prompt = os.path.basename(class_path)\n",
        "        boxes_filt, pred_phrases = get_grounding_output(\n",
        "            model, image, text_prompt, box_threshold, text_threshold, cpu_only=cpu_only, token_spans=eval(\n",
        "                f\"{token_spans}\")\n",
        "        )\n",
        "\n",
        "        # Found bb dimensions\n",
        "\n",
        "        size = image_pil.size\n",
        "        pred_dict = {\n",
        "            \"boxes\": boxes_filt,\n",
        "            \"size\": [size[1], size[0]],  # H, W\n",
        "            \"labels\": pred_phrases,\n",
        "        }\n",
        "\n",
        "        H, W = pred_dict[\"size\"]\n",
        "        boxes = pred_dict[\"boxes\"]\n",
        "        labels = pred_dict[\"labels\"]\n",
        "        assert len(boxes) == len(\n",
        "            labels), \"boxes and labels must have same length\"\n",
        "\n",
        "        draw = ImageDraw.Draw(image_pil)\n",
        "        mask = Image.new(\"L\", image_pil.size, 0)\n",
        "        mask_draw = ImageDraw.Draw(mask)\n",
        "\n",
        "        # change pil image to cv2 image\n",
        "        img = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
        "        img2 = img.copy()\n",
        "        # draw boxes and masks\n",
        "        for box, label in zip(boxes, labels):\n",
        "            # from 0..1 to 0..W, 0..H\n",
        "            box = box * torch.Tensor([W, H, W, H])\n",
        "            # from xywh to xyxy\n",
        "            box[:2] -= box[2:] / 2\n",
        "            box[2:] += box[:2]\n",
        "            # random color\n",
        "            color = tuple(np.random.randint(0, 255, size=1).tolist())\n",
        "            # draw\n",
        "            padding = 10\n",
        "            x0, y0, x1, y1 = box\n",
        "            x0, y0, x1, y1 = int(x0)-padding, int(y0) - \\\n",
        "                padding, int(x1)+padding, int(y1)+padding\n",
        "\n",
        "            # validate if the bounding box is inside the image\n",
        "            if x0 < 0:\n",
        "                x0 = 0\n",
        "            if y0 < 0:\n",
        "                y0 = 0\n",
        "            if x1 > W:\n",
        "                x1 = W\n",
        "            if y1 > H:\n",
        "                y1 = H\n",
        "\n",
        "            # draw rectangles\n",
        "            cv2.rectangle(img2, (x0, y0), (x1, y1), color, 2)\n",
        "\n",
        "            draw.rectangle([x0, y0, x1, y1], outline=color, width=6)\n",
        "            # draw.text((x0, y0), str(label), fill=color)\n",
        "\n",
        "            font = ImageFont.load_default()\n",
        "            if hasattr(font, \"getbbox\"):\n",
        "                bbox = draw.textbbox((x0, y0), str(label), font)\n",
        "            else:\n",
        "                w, h = draw.textsize(str(label), font)\n",
        "                bbox = (x0, y0, w + x0, y0 + h)\n",
        "            # bbox = draw.textbbox((x0, y0), str(label))\n",
        "            draw.rectangle(bbox, fill=color)\n",
        "            draw.text((x0, y0), str(label), fill=\"white\")\n",
        "\n",
        "            mask_draw.rectangle([x0, y0, x1, y1], fill=255, width=6)\n",
        "\n",
        "    # ----------------Start SAM--------------------------------------------------------------\n",
        "\n",
        "            class_name = class_path.split(\"/\")[-1]\n",
        "            sam_bounding_box = np.array([x0, y0, x1, y1])\n",
        "            ran_sam = False\n",
        "            # run sam\n",
        "            if ran_sam == False:\n",
        "                predictor.set_image(img)\n",
        "                ran_sam = True\n",
        "\n",
        "            mask, _, _ = predictor.predict(\n",
        "                point_coords=None,\n",
        "                point_labels=None,\n",
        "                box=sam_bounding_box,\n",
        "                multimask_output=False,\n",
        "            )\n",
        "\n",
        "            mask, _, _ = predictor.predict(\n",
        "                box=sam_bounding_box, multimask_output=False)\n",
        "\n",
        "            # Make png mask\n",
        "            contours, _ = cv2.findContours(mask[0].astype(\n",
        "                np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # Your call to find the contours\n",
        "\n",
        "            # threshold input image using otsu thresholding as mask and refine with morphology\n",
        "            ret, pngmask = cv2.threshold(mask[0].astype(\n",
        "                np.uint8), 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "            kernel = np.ones((9, 9), np.uint8)\n",
        "            pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_CLOSE, kernel)\n",
        "            pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_OPEN, kernel)\n",
        "            result = img.copy()\n",
        "            result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
        "            result[:, :, 3] = pngmask\n",
        "\n",
        "    # ----------------Save Images-----------------------------------------------------------------\n",
        "\n",
        "            if SAVE_BB:\n",
        "                cv2.imwrite(f\"{results_path}/bbs/{class_name}/{imgPath}\", img2)\n",
        "\n",
        "            verify_or_create_dir(f\"{results_path}/{class_name}\")\n",
        "\n",
        "            file_path = f\"{results_path}/{class_name}/{imgPath[:-4]}.png\"\n",
        "            if os.path.exists(file_path):\n",
        "                if os.path.exists(f\"{results_path}/{class_name}/{imgPath[:-4]}_1.png\"):\n",
        "                    if DEBUG:\n",
        "                        print(\"File already exists, saving with _2\")\n",
        "                    cv2.imwrite(\n",
        "                        f\"{results_path}/{class_name}/{imgPath[:-4]}_2.png\", result)\n",
        "                else:\n",
        "                    if DEBUG:\n",
        "                        print(\"File already exists, saving with _1\")\n",
        "                    file_path = f\"{results_path}/{class_name}/{imgPath[:-4]}_1.png\"\n",
        "\n",
        "            cv2.imwrite(file_path, result)\n",
        "            ran_sam = False\n",
        "        i = i + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdpfTufkp4cZ"
      },
      "source": [
        "## Crop processed images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEhhdSJp8ICk",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "def verify_or_create_dir(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "\n",
        "results_path = workdir + \"DS_res/\"\n",
        "path_to_classes = [f.path for f in os.scandir(\n",
        "    workdir + \"processed\") if f.is_dir()]\n",
        "\n",
        "for class_path in path_to_classes:\n",
        "    class_name = os.path.basename(class_path)\n",
        "    verify_or_create_dir(results_path + class_name)\n",
        "    for file_name in os.listdir(class_path):\n",
        "        try:\n",
        "            file_path = class_path + \"/\" + file_name\n",
        "            my_image = Image.open(file_path)\n",
        "            black = Image.new('RGBA', my_image.size)\n",
        "            my_image = Image.composite(my_image, black, my_image)\n",
        "            cropped_image = my_image.crop(my_image.getbbox())\n",
        "            cropped_image.save(f\"{results_path}{class_name}/{file_name}\")\n",
        "            print(f\"{file_name} done\")\n",
        "        except Exception as e:\n",
        "            print(f\"{file_name} failed {e}\")\n",
        "            continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZhU8ZVjp4cZ"
      },
      "source": [
        "## Manually check segmented images\n",
        "\n",
        "Press k to keep an images or d to delete it. You may also use the buttons.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGvQue4zdy0M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "from PIL import Image as PILImage\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# --- CONFIG ---\n",
        "image_dir = workdir + 'DS_res'  # your directory\n",
        "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp')\n",
        "batch_size = 12\n",
        "grid_cols = 4\n",
        "thumb_size = (200, 200)\n",
        "\n",
        "# --- Collect images ---\n",
        "image_paths = []\n",
        "for root, _, files in os.walk(image_dir):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(image_extensions):\n",
        "            full_path = os.path.join(root, file)\n",
        "            if os.path.isfile(full_path):\n",
        "                image_paths.append(full_path)\n",
        "\n",
        "print(f\"Found {len(image_paths)} images\")\n",
        "\n",
        "# --- State ---\n",
        "index = {\"i\": 0}\n",
        "delete_list = []\n",
        "output = widgets.Output()\n",
        "status = widgets.Label()\n",
        "next_button = widgets.Button(description=\"Next Batch\", button_style='primary')\n",
        "delete_button = widgets.Button(\n",
        "    description=\"Delete Selected\", button_style='danger')\n",
        "confirm_delete = widgets.Button(\n",
        "    description=\"Confirm Deletion\", button_style='danger')\n",
        "\n",
        "\n",
        "def show_batch():\n",
        "    output.clear_output(wait=True)\n",
        "\n",
        "    start = index[\"i\"]\n",
        "    end = min(start + batch_size, len(image_paths))\n",
        "    batch = image_paths[start:end]\n",
        "\n",
        "    if not batch:\n",
        "        with output:\n",
        "            print(\"‚úÖ Done reviewing all images.\")\n",
        "            if delete_list:\n",
        "                print(\n",
        "                    f\"üóëÔ∏è {len(delete_list)} images marked for deletion. Click 'Confirm Deletion' to delete.\")\n",
        "            display(confirm_delete)\n",
        "        return\n",
        "\n",
        "    # Create all widgets for the batch\n",
        "    image_checkboxes = []\n",
        "    current_batch_cbs = []  # To store checkboxes for this batch\n",
        "\n",
        "    for img_path in batch:\n",
        "        try:\n",
        "            # Create the checkbox\n",
        "            cb = widgets.Checkbox(\n",
        "                description=f\"{os.path.basename(img_path)}\",\n",
        "                indent=False,\n",
        "                layout=widgets.Layout(width='auto')\n",
        "            )\n",
        "            cb.image_path = img_path\n",
        "            current_batch_cbs.append(cb)\n",
        "\n",
        "            # Load and resize the image\n",
        "            img = PILImage.open(img_path)\n",
        "            img.thumbnail(thumb_size)\n",
        "            buf = io.BytesIO()\n",
        "            img.save(buf, format='PNG')\n",
        "            buf.seek(0)\n",
        "            img_data = buf.getvalue()\n",
        "\n",
        "            # Create image widget\n",
        "            img_widget = widgets.Image(\n",
        "                value=img_data,\n",
        "                format='png',\n",
        "                width=200,\n",
        "                height=200,\n",
        "                layout=widgets.Layout(\n",
        "                    margin='0px'\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # Simple VBox container for image and checkbox\n",
        "            container = widgets.VBox([\n",
        "                img_widget,\n",
        "                cb\n",
        "            ], layout=widgets.Layout(\n",
        "                border='1px solid #ddd',\n",
        "                margin='5px',\n",
        "                padding='5px',\n",
        "                align_items='center'\n",
        "            ))\n",
        "\n",
        "            image_checkboxes.append(container)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {img_path}: {str(e)}\")\n",
        "            # Create an error placeholder with checkbox\n",
        "            error_widget = widgets.HTML(\n",
        "                value=f\"‚ö†Ô∏è Error loading:<br>{os.path.basename(img_path)}\",\n",
        "                layout=widgets.Layout(\n",
        "                    height='200px',\n",
        "                    width='200px',\n",
        "                    display='flex',\n",
        "                    align_items='center',\n",
        "                    justify_content='center'\n",
        "                )\n",
        "            )\n",
        "\n",
        "            cb = widgets.Checkbox(\n",
        "                description=f\"{os.path.basename(img_path)}\",\n",
        "                indent=False,\n",
        "                layout=widgets.Layout(width='auto')\n",
        "            )\n",
        "            cb.image_path = img_path\n",
        "            current_batch_cbs.append(cb)\n",
        "\n",
        "            container = widgets.VBox([\n",
        "                error_widget,\n",
        "                cb\n",
        "            ], layout=widgets.Layout(\n",
        "                border='1px solid #ddd',\n",
        "                margin='5px',\n",
        "                padding='5px',\n",
        "                align_items='center'\n",
        "            ))\n",
        "\n",
        "            image_checkboxes.append(container)\n",
        "\n",
        "    # Store the checkboxes for this batch\n",
        "    output.current_batch_checkboxes = current_batch_cbs\n",
        "\n",
        "    # Rest of your show_batch function remains the same...\n",
        "    # Create grid layout\n",
        "    grid = []\n",
        "    for i in range(0, len(image_checkboxes), grid_cols):\n",
        "        row = image_checkboxes[i:i+grid_cols]\n",
        "        grid.append(widgets.HBox(row))\n",
        "\n",
        "    # Add instructions for the user\n",
        "    instructions = widgets.HTML(\n",
        "        value=\"\"\"\n",
        "        <div style=\"padding: 10px; background-color: #e3f2fd; border-radius: 5px; margin-bottom: 15px;\">\n",
        "            <p><strong>Instructions:</strong> Review the images and select the checkbox below each image you want to delete.\n",
        "            Click \"Delete Selected\" to mark them for deletion and move to the next batch.\n",
        "            When finished, click \"Confirm Deletion\" to permanently delete all marked images.</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with output:\n",
        "        display(instructions)\n",
        "\n",
        "        # Display the grid\n",
        "        for row in grid:\n",
        "            display(row)\n",
        "\n",
        "        # Display buttons\n",
        "        button_box = widgets.HBox([next_button, delete_button, confirm_delete])\n",
        "        display(button_box)\n",
        "        display(status)\n",
        "\n",
        "\n",
        "def on_next_click(_):\n",
        "    index[\"i\"] += batch_size\n",
        "    show_batch()\n",
        "\n",
        "\n",
        "def on_delete_click(_):\n",
        "    # We need to track selected checkboxes differently since the widgets are cleared\n",
        "    # Let's modify show_batch to store the current batch checkboxes\n",
        "    if hasattr(output, 'current_batch_checkboxes'):\n",
        "        selected = [\n",
        "            cb.image_path for cb in output.current_batch_checkboxes if cb.value]\n",
        "        delete_list.extend(selected)\n",
        "        status.value = f\"üóëÔ∏è Marked {len(selected)} new image(s), {len(delete_list)} total for deletion.\"\n",
        "\n",
        "    # Move to next batch\n",
        "    index[\"i\"] += batch_size\n",
        "    show_batch()\n",
        "\n",
        "\n",
        "def delete_images(_):\n",
        "    if not delete_list:\n",
        "        status.value = \"No images selected for deletion.\"\n",
        "        return\n",
        "\n",
        "    deleted = 0\n",
        "    failed = 0\n",
        "\n",
        "    for path in delete_list:\n",
        "        try:\n",
        "            os.remove(path)\n",
        "            deleted += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to delete {path}: {e}\")\n",
        "            failed += 1\n",
        "\n",
        "    status.value = f\"‚úÖ Successfully deleted {deleted} images. {failed} failed.\"\n",
        "    delete_list.clear()\n",
        "\n",
        "    # Refresh the image list\n",
        "    image_paths.clear()\n",
        "    for root, _, files in os.walk(image_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(image_extensions):\n",
        "                full_path = os.path.join(root, file)\n",
        "                if os.path.isfile(full_path):\n",
        "                    image_paths.append(full_path)\n",
        "\n",
        "    index[\"i\"] = 0\n",
        "    show_batch()\n",
        "\n",
        "\n",
        "next_button.on_click(on_next_click)\n",
        "delete_button.on_click(on_delete_click)\n",
        "confirm_delete.on_click(delete_images)\n",
        "\n",
        "display(output)\n",
        "show_batch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlIWZp5np4ca"
      },
      "source": [
        "## Setup for dataset generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJpoRpAsEnD6",
        "outputId": "086fd27a-627d-4f67-d2ed-9634b82de9a4"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "\n",
        "def verify_or_create_dir(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "\n",
        "results_path = workdir + \"DS_res/\"\n",
        "\n",
        "# Get all subfolders inside results_path\n",
        "path_to_classes = [f.path for f in os.scandir(\n",
        "    results_path) if f.is_dir() and \"bbs\" not in f.name]\n",
        "\n",
        "# Build list of (path, class_name) tuples\n",
        "fg_folders = [(path, os.path.basename(path)) for path in path_to_classes]\n",
        "\n",
        "# Define folders\n",
        "bg_folder = workdir + \"bg/\"\n",
        "verify_or_create_dir(bg_folder)\n",
        "output_folder = workdir + \"ds_final/\"\n",
        "objects_list = [os.path.basename(class_path) for class_path in path_to_classes]\n",
        "\n",
        "# If you have a list of original classes, uncomment and fill it\n",
        "original_classes = [\n",
        "    #     \"exampleClass1\", \"exampleClass2\", \"exampleClass3\", \"exampleClass4\",\n",
        "]\n",
        "\n",
        "# Add new classes at the end only\n",
        "all_detected_classes = [os.path.basename(\n",
        "    class_path) for class_path in path_to_classes]\n",
        "\n",
        "# Append only the new classes\n",
        "final_classes = original_classes.copy()\n",
        "for cls in all_detected_classes:\n",
        "    if cls not in final_classes:\n",
        "        final_classes.append(cls)\n",
        "\n",
        "# Create annotations_ID and categories using final_classes\n",
        "annotations_ID = {cls: i for i, cls in enumerate(final_classes)}\n",
        "categories = [{\"id\": i, \"name\": cls} for i, cls in enumerate(final_classes)]\n",
        "\n",
        "print(\"annotations_ID:\", annotations_ID)\n",
        "print(\"categories:\", categories)\n",
        "\n",
        "# Load the list of files in each of the folders\n",
        "fg_files = {}\n",
        "for folder, category in fg_folders:\n",
        "    fg_files[category] = os.listdir(folder)\n",
        "\n",
        "# Define the folder structure\n",
        "subfolders = [\n",
        "    \"train/images\",\n",
        "    \"train/labels\",\n",
        "    \"test/images\",\n",
        "    \"test/labels\",\n",
        "    \"valid/images\",\n",
        "    \"valid/labels\",\n",
        "]\n",
        "\n",
        "# Create them\n",
        "for sub in subfolders:\n",
        "    verify_or_create_dir(os.path.join(output_folder, sub))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBOYwQpeLijp"
      },
      "source": [
        "## Get backgrounds\n",
        "\n",
        "For this step, add background images to ./bg\n",
        "\n",
        "You can run the next cell to download and format a default dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzHBMsQ0R6b0"
      },
      "outputs": [],
      "source": [
        "!pip install kagglehub\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "dataset_path = kagglehub.dataset_download(\"balraj98/stanford-background-dataset\")\n",
        "os.system(f'cp \"{dataset_path}/images/\"* {workdir}bg/')\n",
        "\n",
        "dataset_path = kagglehub.dataset_download(\"adikurniawan/color-dataset-for-color-recognition\")\n",
        "os.system(f'find \"{dataset_path}/training_dataset/\" -type f -exec cp {{}} {workdir}bg/ \\;')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmhTmQubp4ca"
      },
      "source": [
        "## Remove corrupt images\n",
        "\n",
        "You con also remove a percentage of images by modifying _delete_percentage_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyD-Xx4qXLfY",
        "outputId": "2d3d1937-33af-4341-be58-e2b9bd93cb35"
      },
      "outputs": [],
      "source": [
        "delete_percentage = 0  # e.g., 0.1 for 10%\n",
        "debug = False  # Set to True to print deleted files\n",
        "min_width = 0  # Minimum width\n",
        "min_height = 0  # Minimum height\n",
        "\n",
        "\n",
        "def clean_and_trim_dataset(folder):\n",
        "    total_removed = 0\n",
        "    low_res_removed = 0\n",
        "    valid_images = []\n",
        "\n",
        "    # Step 1: Remove corrupt images and low resolution ones\n",
        "    for img_name in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, img_name)\n",
        "        if not os.path.isfile(img_path):\n",
        "            continue\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                img.verify()\n",
        "\n",
        "            with Image.open(img_path) as img:  # reopen to get size\n",
        "                width, height = img.size\n",
        "                if width < min_width or height < min_height:\n",
        "                    if debug:\n",
        "                        print(\n",
        "                            f\"Deleting low resolution image: {img_path} ({width}x{height})\")\n",
        "                    os.remove(img_path)\n",
        "                    low_res_removed += 1\n",
        "                else:\n",
        "                    valid_images.append(img_path)\n",
        "\n",
        "        except (UnidentifiedImageError, OSError):\n",
        "            if debug:\n",
        "                print(f\"Deleting corrupt image: {img_path}\")\n",
        "            os.remove(img_path)\n",
        "            total_removed += 1\n",
        "\n",
        "    print(f\"Removed {total_removed} corrupt images\")\n",
        "    print(f\"Removed {low_res_removed} low resolution images\")\n",
        "\n",
        "    # Step 2: Remove a percentage of the valid images\n",
        "    to_delete_count = int(len(valid_images) * delete_percentage)\n",
        "    to_delete = random.sample(valid_images, to_delete_count)\n",
        "    for img_path in to_delete:\n",
        "        if debug:\n",
        "            print(f\"Deleting random image for dataset reduction: {img_path}\")\n",
        "        os.remove(img_path)\n",
        "\n",
        "    print(f\"Removed {len(to_delete)} images to reduce dataset size\")\n",
        "\n",
        "\n",
        "def count_files_in_dir(directory):\n",
        "    files = [f for f in os.listdir(directory) if os.path.isfile(\n",
        "        os.path.join(directory, f))]\n",
        "    return len(files)\n",
        "\n",
        "\n",
        "# Apply on /content/bg\n",
        "clean_and_trim_dataset(workdir + \"bg\")\n",
        "\n",
        "# Count remaining images\n",
        "print(f\"Remaining number of images: {count_files_in_dir(workdir + 'bg')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rae8Qf1Hp4ca"
      },
      "source": [
        "## Resize bg images\n",
        "\n",
        "Backgrounds don't have to be the best quality, even when scaled up, but they're the canvas for pasting the object images so a good resolution will improve the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqHcFFUGp4ca",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "base_path = workdir + \"bg\"\n",
        "size = 640\n",
        "for filename in os.listdir(base_path):\n",
        "    file_path = os.path.join(base_path, filename)\n",
        "\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            img = img.resize((size, size))\n",
        "            img.save(file_path)\n",
        "    except (UnidentifiedImageError, OSError) as e:\n",
        "        print(f\"Removing corrupt file: {file_path}\")\n",
        "        os.remove(file_path)  # delete corrupt image\n",
        "\n",
        "os.chdir(workdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWV-quChdy0O"
      },
      "source": [
        "## Image generator\n",
        "\n",
        "This cell takes the segmented images of the classes and backgrounds and generate images with a random amount of objects in them scattered around.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiDZbrber25D"
      },
      "outputs": [],
      "source": [
        "# Restart variables\n",
        "workdir = \"/content/drive/MyDrive/RoBorregos/vision/dataset_generator/\"\n",
        "output_folder = workdir + \"ds_final/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3DjdUzK7Lk9T",
        "outputId": "45d3b924-1987-4201-8722-96f6cba854cc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from PIL import Image, ImageDraw, ImageEnhance, ImageFilter, ImageFont, UnidentifiedImageError\n",
        "import numpy as np\n",
        "import yaml\n",
        "\n",
        "images = []\n",
        "annotations = []\n",
        "annotations2 = []\n",
        "annot_csv = []\n",
        "\n",
        "img_id = int(0)\n",
        "anno_id = int(0)\n",
        "\n",
        "min_size_ratio = 0.05  # Objects must be at least 10% of bg size\n",
        "max_size_ratio = 0.35  # Objects can be at most 75% of bg size\n",
        "\n",
        "# Define the maximum overlap as a percentage\n",
        "max_overlap_pct = 25\n",
        "\n",
        "trainfolder = output_folder + \"train/\"\n",
        "validfolder = output_folder + \"valid/\"\n",
        "\n",
        "images_to_generate = 50  # change to 5000\n",
        "max_objects_per_image = 8\n",
        "\n",
        "for j in range(images_to_generate):\n",
        "\n",
        "    with open(f'{trainfolder}labels/{img_id}.txt', 'w') as file:\n",
        "        pass\n",
        "\n",
        "    # Decide if this image should be empty\n",
        "    if random.random() < 0.10:  # 10% chance\n",
        "        num_objects = 0\n",
        "    else:\n",
        "        num_objects = random.randint(1, max_objects_per_image)\n",
        "\n",
        "    fg_categories = random.choices(objects_list, k=num_objects)\n",
        "\n",
        "    fg_files_selected = [[category, random.choice(\n",
        "        fg_files[category])] for category in fg_categories]\n",
        "\n",
        "    fg_imgs = []\n",
        "    for img in fg_files_selected:\n",
        "        folder = [f[0] for f in fg_folders if f[1] == img[0]][0]\n",
        "        fg_img = Image.open(folder + \"/\" + img[1]).convert(\"RGBA\")\n",
        "        fg_imgs.append(\n",
        "            [img[0], Image.open(folder + \"/\" + img[1]), folder + img[1]])\n",
        "\n",
        "    bg_files = os.listdir(bg_folder)\n",
        "    bg_file = random.choice(bg_files)\n",
        "    bg_img = Image.open(bg_folder + bg_file)\n",
        "    bg_img = bg_img.convert(\"RGBA\")\n",
        "\n",
        "    occupied_mask = np.zeros((bg_img.height, bg_img.width), dtype=np.uint8)\n",
        "\n",
        "    for img in fg_imgs:\n",
        "        fg_img = img[1]\n",
        "\n",
        "        angle = random.randint(-5, 5)\n",
        "        fg_img = fg_img.rotate(angle, resample=Image.BICUBIC, expand=True)\n",
        "\n",
        "        # Resize using dynamic scale bounds based on background\n",
        "        original_w, original_h = fg_img.size\n",
        "        max_scale_w = (bg_img.width * max_size_ratio) / original_w\n",
        "        max_scale_h = (bg_img.height * max_size_ratio) / original_h\n",
        "        min_scale_w = (bg_img.width * min_size_ratio) / original_w\n",
        "        min_scale_h = (bg_img.height * min_size_ratio) / original_h\n",
        "\n",
        "        scale_min = max(min_scale_w, min_scale_h)\n",
        "        scale_max = min(max_scale_w, max_scale_h)\n",
        "\n",
        "        # Clamp to [0.01, 1.0] just in case\n",
        "        scale_min = max(scale_min, 0.01)\n",
        "        scale_max = min(scale_max, 1.0)\n",
        "\n",
        "        # If bounds are inverted due to very large fg, clamp both to min_scale\n",
        "        if scale_max < scale_min:\n",
        "            scale_max = scale_min\n",
        "\n",
        "        scale = random.uniform(scale_min, scale_max)\n",
        "\n",
        "        new_w = int(original_w * scale)\n",
        "        new_h = int(original_h * scale)\n",
        "\n",
        "        fg_img = fg_img.resize((new_w, new_h), resample=Image.BICUBIC)\n",
        "\n",
        "        fg_img = ImageEnhance.Brightness(\n",
        "            fg_img).enhance(random.uniform(0.6, 1.4))\n",
        "        fg_img = ImageEnhance.Contrast(\n",
        "            fg_img).enhance(random.uniform(0.8, 1.2))\n",
        "        fg_img = ImageEnhance.Color(fg_img).enhance(random.uniform(0.6, 1.4))\n",
        "        fg_img = fg_img.filter(ImageFilter.GaussianBlur(\n",
        "            radius=random.uniform(0.0, 0.8)))\n",
        "\n",
        "        img[1] = fg_img\n",
        "\n",
        "        max_x = bg_img.width - fg_img.width\n",
        "        max_y = bg_img.height - fg_img.height\n",
        "\n",
        "        for attempt in range(50):\n",
        "            x = random.randint(0, max_x)\n",
        "            y = random.randint(0, max_y)\n",
        "\n",
        "            fg_mask = np.array(fg_img.split()[-1]) > 0\n",
        "\n",
        "            # Make sure dimensions align (especially after rotation/resize)\n",
        "            mask_h, mask_w = fg_mask.shape\n",
        "            if y + mask_h > occupied_mask.shape[0] or x + mask_w > occupied_mask.shape[1]:\n",
        "                continue  # skip if out of bounds (shouldn‚Äôt usually happen)\n",
        "\n",
        "            occ_crop = occupied_mask[y:y + mask_h, x:x + mask_w]\n",
        "            fg_mask_area = np.sum(fg_mask)\n",
        "            occ_crop_area = np.sum(occ_crop)\n",
        "            overlap = np.sum(np.logical_and(fg_mask, occ_crop))\n",
        "\n",
        "            allowed_overlap_fg = max_overlap_pct / 100 * fg_mask_area\n",
        "            allowed_overlap_occ = max_overlap_pct / 100 * \\\n",
        "                occ_crop_area if occ_crop_area > 0 else 0\n",
        "\n",
        "            # Accept placement only if it doesn't cover too much of either\n",
        "            if overlap <= allowed_overlap_fg and overlap <= allowed_overlap_occ:\n",
        "                occupied_mask[y:y + fg_img.height, x:x +\n",
        "                              fg_img.width] = np.logical_or(occ_crop, fg_mask)\n",
        "                break\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        seg_img = fg_img\n",
        "        img_arr = np.array(seg_img)\n",
        "        mask = img_arr[:, :, 3] != 0\n",
        "\n",
        "        segmentation = []\n",
        "        for i in range(mask.shape[0]):\n",
        "            for j in range(mask.shape[1]):\n",
        "                if mask[i, j]:\n",
        "                    segmentation.append(j + x)\n",
        "                    segmentation.append(i + y)\n",
        "        segmentation = [segmentation]\n",
        "\n",
        "        area = abs(sum(\n",
        "            segmentation[0][2 * i] * segmentation[0][(2 * i + 3) % len(segmentation[0])] -\n",
        "            segmentation[0][(2 * i + 2) % len(segmentation[0])\n",
        "                            ] * segmentation[0][2 * i + 1]\n",
        "            for i in range(len(segmentation[0]) // 2)\n",
        "        )) / 2\n",
        "\n",
        "        bg_img.paste(fg_img, (x, y), fg_img)\n",
        "\n",
        "        x1, y1 = x, y\n",
        "        x2 = x + fg_img.width\n",
        "        y2 = y + fg_img.height\n",
        "\n",
        "        if x2 <= x1 or y2 <= y1:\n",
        "            continue\n",
        "\n",
        "        x_center_ann = ((x1 + x2) / 2) / bg_img.width\n",
        "        y_center_ann = ((y1 + y2) / 2) / bg_img.height\n",
        "        width_ann = (x2 - x1) / bg_img.width\n",
        "        height_ann = (y2 - y1) / bg_img.height\n",
        "\n",
        "        if not (0 <= x_center_ann <= 1 and 0 <= y_center_ann <= 1 and 0 <= width_ann <= 1 and 0 <= height_ann <= 1):\n",
        "            continue\n",
        "\n",
        "        # Create segmentation labels\n",
        "        normalize_seg = []\n",
        "        for i in range(len(segmentation[0])):\n",
        "            if i % 2 == 0:\n",
        "                val = segmentation[0][i] / bg_img.width\n",
        "            else:\n",
        "                val = segmentation[0][i] / bg_img.height\n",
        "            normalize_seg.append(str(val))\n",
        "        with open(f'{trainfolder}labels/{img_id}.txt', 'a') as f:\n",
        "            f.write(f\"{annotations_ID[img[0]]} {' '.join(normalize_seg)}\\n\")\n",
        "\n",
        "      # Only bbox labels\n",
        "       # with open(f'{trainfolder}labels/{img_id}.txt', 'a') as f:\n",
        "        #    f.write(f\"{annotations_ID[img[0]]} {x_center_ann} {y_center_ann} {width_ann} {height_ann}\\n\")\n",
        "\n",
        "        annotations2.append({\n",
        "            \"segmentation\": segmentation, \"area\": area, \"iscrowd\": 0,\n",
        "            \"image_id\": img_id, \"bbox\": [x, y, fg_img.width, fg_img.height],\n",
        "            \"category_id\": annotations_ID[img[0]], \"id\": anno_id\n",
        "\n",
        "        })\n",
        "        annotations.append({\n",
        "            \"id\": anno_id, \"image_id\": img_id, \"category_id\": annotations_ID[img[0]],\n",
        "            \"bbox\": [x, y, fg_img.width, fg_img.height],\n",
        "            \"segmentation\": [], \"area\": fg_img.height * fg_img.width, \"iscrowd\": 0\n",
        "        })\n",
        "        annot_csv.append([\n",
        "            \"TRAIN\", output_folder +\n",
        "            str(img_id)+\".jpg\", img[0], x/bg_img.width, y/bg_img.height,\n",
        "            \"\", \"\", (x+fg_img.width) /\n",
        "            bg_img.width, (y+fg_img.height)/bg_img.height\n",
        "        ])\n",
        "\n",
        "        anno_id += 1\n",
        "\n",
        "    bg_img = bg_img.convert(\"RGB\")\n",
        "    bg_img.save(f\"{trainfolder}images/\" + str(img_id) + \".jpg\", quality=100)\n",
        "    images.append({\"id\": img_id, \"file_name\": str(img_id) + \".jpg\",\n",
        "                  \"height\": bg_img.height, \"width\": bg_img.width})\n",
        "    img_id += 1\n",
        "    print(f\"Imagen {img_id} generada correctamente con {num_objects} objetos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6npnbGmYSpb"
      },
      "source": [
        "## Create COCO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzALHbSmr0IT"
      },
      "outputs": [],
      "source": [
        "# Create coco json\n",
        "import json\n",
        "\n",
        "categories = [{\"id\": cid, \"name\": name, \"supercategory\": \"none\"}\n",
        "              for name, cid in annotations_ID.items()]\n",
        "\n",
        "coco_output = {\n",
        "    \"info\": {\n",
        "        \"description\": \"Image Dataset\",\n",
        "        \"version\": \"1.0\",\n",
        "        \"year\": 2025,\n",
        "        \"contributor\": \"\",\n",
        "        \"date_created\": \"2025-07-03\"\n",
        "    },\n",
        "    \"licenses\": [],\n",
        "    \"images\": images,\n",
        "    \"annotations\": annotations2,\n",
        "    \"categories\": categories\n",
        "}\n",
        "\n",
        "with open(f\"{output_folder}annotations_coco.json\", \"w\") as jsonfile:\n",
        "    json.dump(coco_output, jsonfile, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FchQs-I0p4ca"
      },
      "source": [
        "## Check generated images\n",
        "\n",
        "This cell shows n random images from the dataset and draws the bounding boxes from the labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "zHVZeOCzUE3x",
        "outputId": "edc494ac-f9e3-42e8-8346-192d8c0268ca",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display, Javascript, clear_output\n",
        "import ipywidgets as widgets\n",
        "import random\n",
        "# from PIL import Image, ImageDraw, ImageEnhance, ImageFilter, ImageFont, UnidentifiedImageError\n",
        "from PIL import ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "# === CONFIG ===\n",
        "images_dir = workdir + \"ds_final/train/images\"\n",
        "labels_dir = workdir + \"ds_final/train/labels\"\n",
        "num_samples = 15\n",
        "# workdir=\"/content/\"\n",
        "# Get all image files\n",
        "image_files = [f for f in os.listdir(\n",
        "    images_dir) if f.endswith(('.jpg', '.png'))]\n",
        "sampled_files = random.sample(image_files, min(num_samples, len(image_files)))\n",
        "\n",
        "for image_file in sampled_files:\n",
        "    image_path = os.path.join(images_dir, image_file)\n",
        "    label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
        "    label_path = os.path.join(labels_dir, label_file)\n",
        "\n",
        "    # Load image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    img_width, img_height = image.size\n",
        "\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            labels = f.readlines()\n",
        "\n",
        "        for label in labels:\n",
        "            cls, x_center, y_center, w, h = map(float, label.strip().split())\n",
        "            x_center *= img_width\n",
        "            y_center *= img_height\n",
        "            w *= img_width\n",
        "            h *= img_height\n",
        "            x0 = x_center - w / 2\n",
        "            y0 = y_center - h / 2\n",
        "            x1 = x_center + w / 2\n",
        "            y1 = y_center + h / 2\n",
        "            draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=5)\n",
        "            draw.text((x0, y0), str(int(cls)), fill=\"red\")\n",
        "\n",
        "    # Show image with bounding boxes\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image)\n",
        "    plt.title(image_file)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMY4iC9HM6Mm"
      },
      "source": [
        "## Split images\n",
        "\n",
        "Take a percentage of the images and move them to test and validation directories.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vczfmj5OM7Rl",
        "outputId": "30219fa6-3821-42e4-c431-52eb57f12f11"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "validation = 0.1\n",
        "test = 0.1\n",
        "\n",
        "# Assumes train has 100% of data\n",
        "output_folder = workdir + \"ds_final/\"\n",
        "trainfolder = output_folder + \"train/\"\n",
        "trainfolderimgs = trainfolder + \"images/\"\n",
        "trainfolderlabels = trainfolder + \"labels/\"\n",
        "testfolder = output_folder + \"test/\"\n",
        "testfolderimgs = testfolder + \"images/\"\n",
        "testfolderlabels = testfolder + \"labels/\"\n",
        "validfolder = output_folder + \"valid/\"\n",
        "validfolderimgs = validfolder + \"images/\"\n",
        "validfolderlabels = validfolder + \"labels/\"\n",
        "\n",
        "fullSize = len(os.listdir(trainfolderimgs))\n",
        "validSize = int(fullSize * validation)\n",
        "testSize = int(fullSize * test)\n",
        "\n",
        "for i in range(validSize):\n",
        "    filelist = os.listdir(trainfolderimgs)\n",
        "    # randomize file list, to not pick files in order\n",
        "    random.shuffle(filelist)\n",
        "    filetomove = filelist[i]\n",
        "    # take out .jpg, .png, etc\n",
        "    filetomovename = filetomove[:-4]\n",
        "    # move images\n",
        "    shutil.move(f\"{trainfolderimgs}{filetomove}\",\n",
        "                f\"{validfolderimgs}{filetomove}\")\n",
        "    # move labels\n",
        "    shutil.move(f\"{trainfolderlabels}{filetomovename}.txt\",\n",
        "                f\"{validfolderlabels}{filetomovename}.txt\")\n",
        "for i in range(testSize):\n",
        "    filelist = os.listdir(trainfolderimgs)\n",
        "    # randomize file list, to not pick files in order\n",
        "    random.shuffle(filelist)\n",
        "    filetomove = os.listdir(trainfolderimgs)[i]\n",
        "    # take out .jpg, .png, etc\n",
        "    filetomovename = filetomove[:-4]\n",
        "    # move images\n",
        "    shutil.move(f\"{trainfolderimgs}{filetomove}\",\n",
        "                f\"{testfolderimgs}{filetomove}\")\n",
        "    # move labels\n",
        "    shutil.move(f\"{trainfolderlabels}{filetomovename}.txt\",\n",
        "                f\"{testfolderlabels}{filetomovename}.txt\")\n",
        "\n",
        "# Validation\n",
        "print(f\"Train size is now: {len(os.listdir(trainfolderimgs))}\")\n",
        "print(f\"Validation size is now: {len(os.listdir(validfolderimgs))}\")\n",
        "print(f\"Test size is now: {len(os.listdir(testfolderimgs))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO1SbXChAiBs"
      },
      "source": [
        "## Create data.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtYoI5t0Ak1i"
      },
      "outputs": [],
      "source": [
        "# Create data.yaml\n",
        "data = dict(\n",
        "    train=os.path.join(output_folder, \"train\"),\n",
        "    val=os.path.join(output_folder, \"valid\"),\n",
        "    test=os.path.join(output_folder, \"test\"),\n",
        "    nc=len(annotations_ID),\n",
        "    names=list(annotations_ID.keys())\n",
        ")\n",
        "\n",
        "with open(f'{output_folder}data.yaml', 'w') as outfile:\n",
        "    yaml.dump(data, outfile, default_flow_style=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGyMZpYMEjiq"
      },
      "source": [
        "## Train a yolo model with the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gQ767sidy0P"
      },
      "source": [
        "Clean invalid labels and then train yolo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gOyra8VE0-0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\" # for some systems\n",
        "from ultralytics import YOLO\n",
        "\n",
        "os.chdir(workdir)\n",
        "\n",
        "# Load a YOLOv8 model (you can also use 'yolov8n.yaml', 'yolov8s.yaml', etc.)\n",
        "model = YOLO(\"yolo11m.yaml\")  # \"yolo11m.yaml\"\n",
        "\n",
        "# Train the model\n",
        "model.train(\n",
        "    data=workdir + \"ds_final/data.yaml\",\n",
        "    epochs=20,  # change to 200\n",
        "    imgsz=128,\n",
        "    batch=32,  # 32, 64, 128 or -1\n",
        "    # degrees=15,\n",
        "    # translate=0.1,\n",
        "    # shear=5,\n",
        "    # scale=0.5,\n",
        "    # perspective=0.001,\n",
        "    # flipud=0.3,\n",
        "    # fliplr=0.5,\n",
        "    # mosaic=1.0,\n",
        "    # mixup=0.2,\n",
        "    # copy_paste=0.1\n",
        "    patience=25,\n",
        "    save_period=10,\n",
        "    cache=True,\n",
        "    amp=True,\n",
        "    device='cpu'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TY83CIQaFcPO",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "os.chdir(workdir)\n",
        "\n",
        "# Load the best trained model\n",
        "model = YOLO(workdir + \"runs/detect/train15/weights/best.pt\")\n",
        "\n",
        "# Run inference on test images\n",
        "results = model.predict(\n",
        "    source=workdir + \"ds_final/test/images\", save=True, conf=0.5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "z0XKknj0p4cY",
        "FBqfbPuhp4cY",
        "mFg8rFwzp4cY",
        "wgHibh11p4cY",
        "ZdpfTufkp4cZ",
        "pZhU8ZVjp4cZ",
        "WBOYwQpeLijp",
        "MmhTmQubp4ca",
        "rae8Qf1Hp4ca",
        "FchQs-I0p4ca"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
