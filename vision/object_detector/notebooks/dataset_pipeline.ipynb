{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/RoBorregos/home-pipelines/blob/vision-dataset/vision/object_detector/notebooks/dataset_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eF2AaAk1IEaV"
   },
   "source": [
    "# Object detector dataset generator\n",
    "\n",
    "With this notebook you'll be able to artificially generate and automatically label\n",
    "a dataset for detecting objects. You can bring your own images or test it by fetching images from Kaggle hub.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCK-uHgydy0J"
   },
   "source": [
    "If running on colab, install dependencies:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BwpM1sG-6vw",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install numpy opencv-python pillow pycocotools pyyaml torch ultralytics matplotlib imutils argparse groundingdino-py segment-anything numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ou32WeHhVHR"
   },
   "source": [
    "If you want to mount your google drive for training with checkpoints in colab and saving your progress run the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRE8LH5WIGhh",
    "outputId": "600e4995-bdad-4b08-aa1b-c2ebd9c8c1c0"
   },
   "outputs": [],
   "source": [
    "!rm -rf /content/sample_data\n",
    "!rm -rf /content/.config\n",
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content', force_remount=True)\n",
    "workdir = \"/content/MyDrive/RoBorregos/vision/dataset_generator/\"\n",
    "os.makedirs(workdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jw61UICTMCIk"
   },
   "source": [
    "If not mounting a drive run the next cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZoFECOyL7zi"
   },
   "outputs": [],
   "source": [
    "workdir = \"/home/fernando/Documents/SAM3/home-pipelines/vision/object_detector/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OFGYuTSq-c5M",
    "outputId": "b3a6be46-6d17-4e82-caab-16a27f7a9048"
   },
   "outputs": [],
   "source": [
    "from groundingdino.util.vl_utils import create_positive_map_from_span\n",
    "from groundingdino.util.utils import clean_state_dict, get_phrases_from_posmap\n",
    "from groundingdino.util.slconfig import SLConfig\n",
    "from groundingdino.util.inference import load_model, predict\n",
    "from groundingdino.util import box_ops\n",
    "from groundingdino.models import build_model\n",
    "import groundingdino.datasets.transforms as T\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import ultralytics\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import csv\n",
    "import yaml\n",
    "from pycocotools import mask\n",
    "from PIL import Image, ImageDraw, ImageEnhance, ImageFilter, ImageFont, UnidentifiedImageError\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "os.chdir(\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5oN4FDoBSwW"
   },
   "source": [
    "# Attention!\n",
    "\n",
    "If you have specific pictures, place the folders in ./images and skip the next two blocks of code which download a default dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kbz7bnpTIx6a",
    "outputId": "79c76471-af2a-44a8-d0c5-203dc0cf68b7"
   },
   "outputs": [],
   "source": [
    "!pip install kagglehub\n",
    "import kagglehub\n",
    "\n",
    "dataset_path = kagglehub.dataset_download(\"bhavikjikadara/dog-and-cat-classification-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V38GLZoAAnGw",
    "outputId": "0402682a-8849-46c7-ad6e-9fe506106999"
   },
   "outputs": [],
   "source": [
    "!cp -r {dataset_path}/PetImages {workdir}\n",
    "!mv {workdir}/PetImages {workdir}/images\n",
    "\n",
    "def clean_and_trim_dataset(folder):\n",
    "    total_removed = 0\n",
    "\n",
    "    for category in [\"Cat\", \"Dog\"]:\n",
    "        path = os.path.join(folder, category)\n",
    "        valid_images = []\n",
    "\n",
    "        # Step 1: Remove corrupt images\n",
    "        for img_name in os.listdir(path):\n",
    "            img_path = os.path.join(path, img_name)\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    img.verify()\n",
    "                valid_images.append(img_path)\n",
    "            except (UnidentifiedImageError, OSError):\n",
    "                os.remove(img_path)\n",
    "                total_removed += 1\n",
    "\n",
    "        print(f\"Removed {total_removed} corrupt images from {category}\")\n",
    "\n",
    "        # Step 2: Remove part of the remaining valid images\n",
    "        to_delete = random.sample(valid_images, len(valid_images) * 99 // 100)\n",
    "        for img_path in to_delete:\n",
    "            os.remove(img_path)\n",
    "\n",
    "        print(f\"Removed {len(to_delete)} images from {category} to reduce dataset size\")\n",
    "\n",
    "clean_and_trim_dataset(workdir + \"images\")\n",
    "\n",
    "def count_files_in_dir(directory):\n",
    "    # List all files (images) in the directory and count them\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    return len(files)\n",
    "\n",
    "# Example usage for \"Cat\" and \"Dog\" folders\n",
    "cat_folder = workdir + \"images/Cat\"\n",
    "dog_folder = workdir + \"images/Dog\"\n",
    "\n",
    "print(f\"Number of cat images: {count_files_in_dir(cat_folder)}\")\n",
    "print(f\"Number of dog images: {count_files_in_dir(dog_folder)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop images to 1:1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, UnidentifiedImageError, ImageOps\n",
    "import os\n",
    "\n",
    "base_path = workdir + \"images\"\n",
    "\n",
    "for class_dir in os.listdir(base_path):\n",
    "    class_path = os.path.join(base_path, class_dir)\n",
    "\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    print(class_path)\n",
    "    for filename in os.listdir(class_path):\n",
    "        file_path = os.path.join(class_path, filename)\n",
    "\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                # Apply EXIF orientation\n",
    "                img = ImageOps.exif_transpose(img)\n",
    "\n",
    "                width, height = img.size\n",
    "                min_dim = min(width, height)\n",
    "\n",
    "                left = (width - min_dim) // 2\n",
    "                top = (height - min_dim) // 2\n",
    "                right = left + min_dim\n",
    "                bottom = top + min_dim\n",
    "\n",
    "                img_cropped = img.crop((left, top, right, bottom))\n",
    "                img_cropped.save(file_path)\n",
    "        except (UnidentifiedImageError, OSError) as e:\n",
    "            print(f\"Removing corrupt file: {file_path}\")\n",
    "            os.remove(file_path)\n",
    "\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize images\n",
    "\n",
    "If tight on time, consider resizing down the images for faster segmentation and other processes, if not skip this step for better dataset quality (considering the images are high resolution).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_q0rbC8z1np",
    "outputId": "9b407969-3551-42f3-d17a-5665be036fa6"
   },
   "outputs": [],
   "source": [
    "base_path = workdir + \"images\"\n",
    "size = 1280\n",
    "\n",
    "for class_dir in os.listdir(base_path):\n",
    "    class_path = os.path.join(base_path, class_dir)\n",
    "\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    print(class_path)\n",
    "    for filename in os.listdir(class_path):\n",
    "        file_path = os.path.join(class_path, filename)\n",
    "\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                img = img.resize((size, size))\n",
    "                img.save(file_path)\n",
    "        except (UnidentifiedImageError, OSError) as e:\n",
    "            print(f\"Removing corrupt file: {file_path}\")\n",
    "            os.remove(file_path)  # delete corrupt image\n",
    "\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate images\n",
    "\n",
    "If needed rotate the image an amount of degrees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "angle = 90\n",
    "\n",
    "\n",
    "def rotate_images_in_directory(directory):\n",
    "    count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    rotated = img.rotate(angle, expand=True)\n",
    "                    rotated.save(filepath)\n",
    "                    count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "    print(f\"Rotated {count} images in {directory}\")\n",
    "\n",
    "\n",
    "def rotate_all_subdirs(base_directory):\n",
    "    for subdir in os.listdir(base_directory):\n",
    "        subdir_path = os.path.join(base_directory, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            rotate_images_in_directory(subdir_path)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# rotate_all_subdirs(os.path.join(workdir, \"processed/Apple\"))\n",
    "rotate_images_in_directory(workdir + \"processed/Soap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2Nl0FnupalH"
   },
   "source": [
    "## Download models\n",
    "\n",
    "If you have already ran this and are using a volume/drive there is no need to run again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ldTlMrhBbZ1m",
    "outputId": "005ef2b0-12cd-422b-c7bc-7550889d5ac4"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
    "!wget https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n",
    "!git clone https://github.com/facebookresearch/sam3.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d69bb9ad91f648e29cc9dfff69e7728e",
      "c05faa28b73b4af5942dcaa183aa0d23",
      "478de8615e99440bb8c2c46abc682138",
      "5049c90d37d54420b3dddc119adb99ba",
      "af9c10f0df6c4bc5a63ea9fc18fef6a3",
      "b1a4231b6ad34afa9d7730ed4a03b2d3",
      "ef258e82c4f941f296c9628628a2aab9",
      "590eff2c9bf94a408824b5ab424b1d86",
      "6c319048ba704dc8999f93ac2e3983c0",
      "2e7c6e1d2ce540a0947bd23a4eefaeb5",
      "a9b569e9cfbc427899642a4d04a40511",
      "32dd7428aaca4873b1372fc3d53d86f3",
      "9c63dd84d492454a9db035417904badf",
      "57b147ec95bd4a5281182a5593cede2d",
      "e0a1d9fc6acb4c48b673af883342ca14",
      "a4e0fbc727a74f99899ed75b38ddf475",
      "c2543c38f7a64a5896a0575aea4b9aea",
      "6199d41041f84bd88b19c542d91b737b",
      "9d7f44fe4a3e42fba2d7f366b2cbdb35",
      "715dcfb65f2847bba07cd70e87fef753",
      "a4bf668dc0144abf9612f84a6852a810",
      "66502c3a78ba4d7493c596643756f984",
      "10cc1d0e80a64ae9a74e26cf271d4e3c",
      "5a31bb492ac14114a4834ce01606c215",
      "d17bbb777f684b2ab3218437fa3addac",
      "5040ef2b0be949f29b9bb14501766d8c",
      "9a6dd1b69c534089ae76de0c7066f536",
      "bdf7fc5abe5c4f66a43087c6983d7a08",
      "62d815b28d6c44f6a7929937e1d946da",
      "ac52a1e1fdc24daba3fa3e83c3bde187",
      "91c04aac570a4afba58c56556b073299",
      "bc6a084b27bf43199133a983c0e998d9",
      "8240eac68b4e486fabfb7bc0e6ede318",
      "2c023625bc6646918480dd004b28d9d1",
      "afa32ee98b66461bb78372e6d7a1cc3e",
      "3ea1c1a5199f4d18a23984669bd64f70",
      "673756d1faf649ce8a73542506330efa",
      "d4a4280d6bad475eb85ce1c34bdc8b4b",
      "39ed14f4c1744d47ab5a6501d7ceb066",
      "db34ee159254442988370a564c2c22aa",
      "a843a7504f59438498c3d387300258c0",
      "32e982541d2d4a42b8ec741069277148",
      "758b5e025dd64b5eaaad54d6bde5b1a8",
      "3dc907d3dd9d46f4a0a6602cfdbcb5c5",
      "8afcd9a2728e49249d131455ca90b387",
      "fe65928650c441ff9f7862bb9f0252ca",
      "3cc6e765638b4c8693ad1939adbc7075",
      "65b1f7e1f7574badb642231988b7971f",
      "21e1b46e14754b2c89fd9fb3e02447ef",
      "074ac668b1874d7898bb48eb8c1e5609",
      "07aa5b72d67a4406a36158ac73052965",
      "0674519ce3f94cb2af1795284ac5c254",
      "4f5befeb518141d78d8ab648b7aac290",
      "df27dfcd46794ebba579ccdc5d917356",
      "1b3e6578daa14e878fa81b49be27a1c9"
     ]
    },
    "id": "2-G0iL0HJywT",
    "outputId": "0ba260a4-19e1-44b9-c83e-31c8c272b4d4"
   },
   "outputs": [],
   "source": [
    "SAVE_BB = False\n",
    "DEBUG = False\n",
    "\n",
    "# path to save results already processed and segmented images\n",
    "results_path = workdir + \"processed\"\n",
    "# change the path of the model config file\n",
    "config_file = workdir + \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "# change the path of the model\n",
    "checkpoint_path = workdir + \"groundingdino_swint_ogc.pth\"\n",
    "output_dir = results_path\n",
    "box_threshold = 0.3\n",
    "text_threshold = 0.25\n",
    "token_spans = None\n",
    "sam3_score_threshold = 0.4\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from sam3.model_builder import build_sam3_image_model\n",
    "from sam3.model.sam3_image_processor import Sam3Processor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} for GroundingDINO + SAM3\")\n",
    "\n",
    "sam3_checkpoint = workdir + \"sam3.pt\"\n",
    "if not os.path.exists(sam3_checkpoint):\n",
    "    raise FileNotFoundError(\n",
    "        f\"SAM3 checkpoint not found at {sam3_checkpoint}. Please download it before running this pipeline.\"\n",
    "    )\n",
    "\n",
    "sam3_model = build_sam3_image_model(\n",
    "    device=device,\n",
    "    eval_mode=True,\n",
    "    checkpoint_path=sam3_checkpoint,\n",
    "    load_from_HF=False,\n",
    ")\n",
    "sam3_processor = Sam3Processor(\n",
    "    sam3_model,\n",
    "    device=device,\n",
    "    confidence_threshold=sam3_score_threshold,\n",
    ")\n",
    "\n",
    "images = []\n",
    "annotations = []\n",
    "categories = []\n",
    "\n",
    "img_id = 0\n",
    "anno_id = 0\n",
    "\n",
    "# Make a list of all the directories in the path\n",
    "base_path = workdir + \"images\"\n",
    "path_to_classes = [f.path for f in os.scandir(base_path) if f.is_dir()]\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "\n",
    "    image_pil = Image.open(image_path).convert(\"RGB\")  # load image\n",
    "\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.RandomResize([800], max_size=1333),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    image, _ = transform(image_pil, None)  # 3, h, w\n",
    "    return image_pil, image\n",
    "\n",
    "\n",
    "def load_model(model_config_path, model_checkpoint_path, cpu_only=False):\n",
    "    args = SLConfig.fromfile(model_config_path)\n",
    "    args.device = device\n",
    "    model = build_model(args)\n",
    "    checkpoint = torch.load(model_checkpoint_path, map_location=\"cpu\")\n",
    "    load_res = model.load_state_dict(\n",
    "        clean_state_dict(checkpoint[\"model\"]), strict=False)\n",
    "    if DEBUG:\n",
    "        print(load_res)\n",
    "    _ = model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_grounding_output(model, image, caption, box_threshold, text_threshold=None, with_logits=True, cpu_only=False, token_spans=None):\n",
    "    assert text_threshold is not None or token_spans is not None, \"text_threshould and token_spans should not be None at the same time!\"\n",
    "    caption = caption.lower()\n",
    "    caption = caption.strip()\n",
    "    if not caption.endswith(\".\"):\n",
    "        caption = caption + \".\"\n",
    "    model = model.to(device)\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        if DEBUG:\n",
    "            print(\"Running model...\")\n",
    "        outputs = model(image[None], captions=[caption])\n",
    "    logits = outputs[\"pred_logits\"].sigmoid()[0]  # (nq, 256)\n",
    "    boxes = outputs[\"pred_boxes\"][0]  # (nq, 4)\n",
    "\n",
    "    # filter output\n",
    "    if token_spans is None:\n",
    "        logits_filt = logits.cpu().clone()\n",
    "        boxes_filt = boxes.cpu().clone()\n",
    "        filt_mask = logits_filt.max(dim=1)[0] > box_threshold\n",
    "        logits_filt = logits_filt[filt_mask]  # num_filt, 256\n",
    "        boxes_filt = boxes_filt[filt_mask]  # num_filt, 4\n",
    "\n",
    "        # get phrase\n",
    "        tokenlizer = model.tokenizer\n",
    "        tokenized = tokenlizer(caption)\n",
    "        # build pred\n",
    "        pred_phrases = []\n",
    "        for logit, box in zip(logits_filt, boxes_filt):\n",
    "            pred_phrase = get_phrases_from_posmap(\n",
    "                logit > text_threshold, tokenized, tokenlizer)\n",
    "            if with_logits:\n",
    "                pred_phrases.append(\n",
    "                    pred_phrase + f\"({str(logit.max().item())[:4]})\")\n",
    "            else:\n",
    "                pred_phrases.append(pred_phrase)\n",
    "    else:\n",
    "        # given-phrase mode\n",
    "        positive_maps = create_positive_map_from_span(\n",
    "            model.tokenizer(text_prompt),\n",
    "            token_span=token_spans\n",
    "        ).to(image.device)  # n_phrase, 256\n",
    "\n",
    "        logits_for_phrases = positive_maps @ logits.T  # n_phrase, nq\n",
    "        all_logits = []\n",
    "        all_phrases = []\n",
    "        all_boxes = []\n",
    "        for (token_span, logit_phr) in zip(token_spans, logits_for_phrases):\n",
    "            # get phrase\n",
    "            phrase = ' '.join([caption[_s:_e] for (_s, _e) in token_span])\n",
    "            # get mask\n",
    "            filt_mask = logit_phr > box_threshold\n",
    "            # filt box\n",
    "            all_boxes.append(boxes[filt_mask])\n",
    "            # filt logits\n",
    "            all_logits.append(logit_phr[filt_mask])\n",
    "            if with_logits:\n",
    "                logit_phr_num = logit_phr[filt_mask]\n",
    "                all_phrases.extend(\n",
    "                    [phrase + f\"({str(logit.item())[:4]})\" for logit in logit_phr_num])\n",
    "            else:\n",
    "                all_phrases.extend([phrase for _ in range(len(filt_mask))])\n",
    "        boxes_filt = torch.cat(all_boxes, dim=0).cpu()\n",
    "        pred_phrases = all_phrases\n",
    "    return boxes_filt, pred_phrases\n",
    "\n",
    "\n",
    "def verify_or_create_dir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    if DEBUG:\n",
    "        print(f\"Verified/created: {path}\")\n",
    "\n",
    "\n",
    "def count_all_files_in_dir(directory):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        count += len([f for f in files if os.path.isfile(os.path.join(root, f))])\n",
    "    return count\n",
    "\n",
    "\n",
    "def normalize_xyxy_to_cxcywh(x0, y0, x1, y1, width, height):\n",
    "    width = max(float(width), 1e-6)\n",
    "    height = max(float(height), 1e-6)\n",
    "    cx = ((x0 + x1) / 2.0) / width\n",
    "    cy = ((y0 + y1) / 2.0) / height\n",
    "    w = (x1 - x0) / width\n",
    "    h = (y1 - y0) / height\n",
    "\n",
    "    def clamp(value):\n",
    "        return max(0.0, min(1.0, float(value)))\n",
    "\n",
    "    return [\n",
    "        clamp(cx),\n",
    "        clamp(cy),\n",
    "        clamp(max(w, 1e-6)),\n",
    "        clamp(max(h, 1e-6)),\n",
    "    ]\n",
    "\n",
    "\n",
    "# Get total number of images to process\n",
    "image_dir = workdir + \"images\"\n",
    "number_of_images = count_all_files_in_dir(image_dir)\n",
    "print(f\"Total image files: {number_of_images}\")\n",
    "\n",
    "# Check if results directory exists, else create it\n",
    "verify_or_create_dir(results_path)\n",
    "\n",
    "# Image_path = args.image_path\n",
    "cpu_only = False if torch.cuda.is_available() else True\n",
    "\n",
    "# Load model\n",
    "model = load_model(config_file, checkpoint_path, cpu_only=cpu_only)\n",
    "\n",
    "# Main loop\n",
    "i = 0\n",
    "for class_path in path_to_classes:\n",
    "    class_name = os.path.basename(class_path)\n",
    "    imgPaths = os.listdir(class_path)\n",
    "    if SAVE_BB:\n",
    "        verify_or_create_dir(f\"{results_path}/bbs/{class_name}\")\n",
    "\n",
    "    for imgPath in imgPaths:\n",
    "        if DEBUG:\n",
    "            print(f\"Processing image: {imgPath}\")\n",
    "        print(f\"%{i * 100 / number_of_images}\")\n",
    "        img = imutils.resize(cv2.imread(f\"{class_path}/{imgPath}\"))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "    # ------------------------start grounding----------------------------------------------\n",
    "\n",
    "        # Load image\n",
    "        image_pil, image = load_image(f\"{class_path}/{imgPath}\")\n",
    "\n",
    "        # Set the text_threshold to None if token_spans is set.\n",
    "        if token_spans is not None:\n",
    "            text_threshold = None\n",
    "            print(\"Using token_spans. Set the text_threshold to None.\")\n",
    "\n",
    "        # Run model\n",
    "        text_prompt = os.path.basename(class_path)\n",
    "        boxes_filt, pred_phrases = get_grounding_output(\n",
    "            model, image, text_prompt, box_threshold, text_threshold, cpu_only=cpu_only, token_spans=eval(\n",
    "                f\"{token_spans}\")\n",
    "        )\n",
    "\n",
    "        # Found bb dimensions\n",
    "\n",
    "        size = image_pil.size\n",
    "        pred_dict = {\n",
    "            \"boxes\": boxes_filt,\n",
    "            \"size\": [size[1], size[0]],  # H, W\n",
    "            \"labels\": pred_phrases,\n",
    "        }\n",
    "\n",
    "        H, W = pred_dict[\"size\"]\n",
    "        boxes = pred_dict[\"boxes\"]\n",
    "        labels = pred_dict[\"labels\"]\n",
    "        assert len(boxes) == len(\n",
    "            labels), \"boxes and labels must have same length\"\n",
    "\n",
    "        draw = ImageDraw.Draw(image_pil)\n",
    "        mask = Image.new(\"L\", image_pil.size, 0)\n",
    "        mask_draw = ImageDraw.Draw(mask)\n",
    "\n",
    "        # change pil image to cv2 image\n",
    "        img = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
    "        img2 = img.copy()\n",
    "\n",
    "        sam3_state = sam3_processor.set_image(image_pil.copy())\n",
    "        sam3_state = sam3_processor.set_text_prompt(\n",
    "            prompt=text_prompt,\n",
    "            state=sam3_state,\n",
    "        )\n",
    "\n",
    "        # draw boxes and masks\n",
    "        for box, label in zip(boxes, labels):\n",
    "            # from 0..1 to 0..W, 0..H\n",
    "            box = box * torch.Tensor([W, H, W, H])\n",
    "            # from xywh to xyxy\n",
    "            box[:2] -= box[2:] / 2\n",
    "            box[2:] += box[:2]\n",
    "            # random color\n",
    "            color = tuple(np.random.randint(0, 255, size=1).tolist())\n",
    "            # draw\n",
    "            padding = 10\n",
    "            x0, y0, x1, y1 = box\n",
    "            x0, y0, x1, y1 = int(x0)-padding, int(y0) - \\\n",
    "                padding, int(x1)+padding, int(y1)+padding\n",
    "\n",
    "            # validate if the bounding box is inside the image\n",
    "            if x0 < 0:\n",
    "                x0 = 0\n",
    "            if y0 < 0:\n",
    "                y0 = 0\n",
    "            if x1 > W:\n",
    "                x1 = W\n",
    "            if y1 > H:\n",
    "                y1 = H\n",
    "\n",
    "            # draw rectangles\n",
    "            cv2.rectangle(img2, (x0, y0), (x1, y1), color, 2)\n",
    "\n",
    "            draw.rectangle([x0, y0, x1, y1], outline=color, width=6)\n",
    "            # draw.text((x0, y0), str(label), fill=color)\n",
    "\n",
    "            font = ImageFont.load_default()\n",
    "            if hasattr(font, \"getbbox\"):\n",
    "                bbox = draw.textbbox((x0, y0), str(label), font)\n",
    "            else:\n",
    "                w, h = draw.textsize(str(label), font)\n",
    "                bbox = (x0, y0, w + x0, y0 + h)\n",
    "            # bbox = draw.textbbox((x0, y0), str(label))\n",
    "            draw.rectangle(bbox, fill=color)\n",
    "            draw.text((x0, y0), str(label), fill=\"white\")\n",
    "\n",
    "            mask_draw.rectangle([x0, y0, x1, y1], fill=255, width=6)\n",
    "\n",
    "    # ----------------Start SAM--------------------------------------------------------------\n",
    "\n",
    "            normalized_box = normalize_xyxy_to_cxcywh(x0, y0, x1, y1, W, H)\n",
    "            sam3_state[\"geometric_prompt\"] = sam3_processor.model._get_dummy_prompt()\n",
    "            sam3_state = sam3_processor.add_geometric_prompt(\n",
    "                box=normalized_box,\n",
    "                label=True,\n",
    "                state=sam3_state,\n",
    "            )\n",
    "\n",
    "            masks_tensor = sam3_state.get(\"masks\")\n",
    "            scores_tensor = sam3_state.get(\"scores\")\n",
    "            if (\n",
    "                masks_tensor is None\n",
    "                or scores_tensor is None\n",
    "                or masks_tensor.nelement() == 0\n",
    "            ):\n",
    "                if DEBUG:\n",
    "                    print(f\"SAM3 did not return masks for bounding box {normalized_box}\")\n",
    "                continue\n",
    "\n",
    "            best_idx = int(torch.argmax(scores_tensor).item())\n",
    "            sam_mask = (\n",
    "                masks_tensor[best_idx, 0]\n",
    "                .detach()\n",
    "                .to(\"cpu\")\n",
    "                .numpy()\n",
    "                .astype(np.uint8)\n",
    "            )\n",
    "\n",
    "            # Make png mask\n",
    "            contours, _ = cv2.findContours(sam_mask.astype(\n",
    "                np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # Your call to find the contours\n",
    "\n",
    "            # threshold input image using otsu thresholding as mask and refine with morphology\n",
    "            ret, pngmask = cv2.threshold(sam_mask.astype(\n",
    "                np.uint8), 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "            kernel = np.ones((9, 9), np.uint8)\n",
    "            pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_CLOSE, kernel)\n",
    "            pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_OPEN, kernel)\n",
    "            result = img.copy()\n",
    "            result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "            result[:, :, 3] = pngmask\n",
    "\n",
    "    # ----------------Save Images-----------------------------------------------------------------\n",
    "\n",
    "            if SAVE_BB:\n",
    "                cv2.imwrite(f\"{results_path}/bbs/{class_name}/{imgPath}\", img2)\n",
    "\n",
    "            verify_or_create_dir(f\"{results_path}/{class_name}\")\n",
    "\n",
    "            file_path = f\"{results_path}/{class_name}/{imgPath[:-4]}.png\"\n",
    "            if os.path.exists(file_path):\n",
    "                if os.path.exists(f\"{results_path}/{class_name}/{imgPath[:-4]}_1.png\"):\n",
    "                    if DEBUG:\n",
    "                        print(\"File already exists, saving with _2\")\n",
    "                    cv2.imwrite(\n",
    "                        f\"{results_path}/{class_name}/{imgPath[:-4]}_2.png\", result)\n",
    "                else:\n",
    "                    if DEBUG:\n",
    "                        print(\"File already exists, saving with _1\")\n",
    "                    file_path = f\"{results_path}/{class_name}/{imgPath[:-4]}_1.png\"\n",
    "\n",
    "            cv2.imwrite(file_path, result)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop processed images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEhhdSJp8ICk",
    "outputId": "c92316db-fc6d-4b33-8fde-bca8fe5575d1"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def verify_or_create_dir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "results_path = workdir + \"DS_res/\"\n",
    "path_to_classes = [f.path for f in os.scandir(\n",
    "    workdir + \"processed\") if f.is_dir()]\n",
    "\n",
    "for class_path in path_to_classes:\n",
    "    class_name = os.path.basename(class_path)\n",
    "    verify_or_create_dir(results_path + class_name)\n",
    "    for file_name in os.listdir(class_path):\n",
    "        try:\n",
    "            file_path = class_path + \"/\" + file_name\n",
    "            my_image = Image.open(file_path)\n",
    "            black = Image.new('RGBA', my_image.size)\n",
    "            my_image = Image.composite(my_image, black, my_image)\n",
    "            cropped_image = my_image.crop(my_image.getbbox())\n",
    "            cropped_image.save(f\"{results_path}{class_name}/{file_name}\")\n",
    "            print(f\"{file_name} done\")\n",
    "        except Exception as e:\n",
    "            print(f\"{file_name} failed {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually check segmented images\n",
    "\n",
    "Press k to keep an images or d to delete it. You may also use the buttons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d17446d0068147e19fdd846f9d3ab174",
      "ec09dccd6cf44636a52611d405a8a849",
      "2353f8accbe1428b8c436045a902fe39"
     ]
    },
    "id": "TGvQue4zdy0M",
    "outputId": "cea4a763-6f4b-4f4f-c4e3-7958f145c58b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "from PIL import Image as PILImage\n",
    "import io\n",
    "import base64\n",
    "\n",
    "# --- CONFIG ---\n",
    "image_dir = workdir + 'DS_res'  # your directory\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp')\n",
    "batch_size = 12\n",
    "grid_cols = 4\n",
    "thumb_size = (200, 200)\n",
    "\n",
    "# --- Collect images ---\n",
    "image_paths = []\n",
    "for root, _, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(image_extensions):\n",
    "            full_path = os.path.join(root, file)\n",
    "            if os.path.isfile(full_path):\n",
    "                image_paths.append(full_path)\n",
    "\n",
    "print(f\"Found {len(image_paths)} images\")\n",
    "\n",
    "# --- State ---\n",
    "index = {\"i\": 0}\n",
    "delete_list = []\n",
    "output = widgets.Output()\n",
    "status = widgets.Label()\n",
    "next_button = widgets.Button(description=\"Next Batch\", button_style='primary')\n",
    "delete_button = widgets.Button(\n",
    "    description=\"Delete Selected\", button_style='danger')\n",
    "confirm_delete = widgets.Button(\n",
    "    description=\"Confirm Deletion\", button_style='danger')\n",
    "\n",
    "\n",
    "def show_batch():\n",
    "    output.clear_output(wait=True)\n",
    "\n",
    "    start = index[\"i\"]\n",
    "    end = min(start + batch_size, len(image_paths))\n",
    "    batch = image_paths[start:end]\n",
    "\n",
    "    if not batch:\n",
    "        with output:\n",
    "            print(\"‚úÖ Done reviewing all images.\")\n",
    "            if delete_list:\n",
    "                print(\n",
    "                    f\"üóëÔ∏è {len(delete_list)} images marked for deletion. Click 'Confirm Deletion' to delete.\")\n",
    "            display(confirm_delete)\n",
    "        return\n",
    "\n",
    "    # Create all widgets for the batch\n",
    "    image_checkboxes = []\n",
    "    current_batch_cbs = []  # To store checkboxes for this batch\n",
    "\n",
    "    for img_path in batch:\n",
    "        try:\n",
    "            # Create the checkbox\n",
    "            cb = widgets.Checkbox(\n",
    "                description=f\"{os.path.basename(img_path)}\",\n",
    "                indent=False,\n",
    "                layout=widgets.Layout(width='auto')\n",
    "            )\n",
    "            cb.image_path = img_path\n",
    "            current_batch_cbs.append(cb)\n",
    "\n",
    "            # Load and resize the image\n",
    "            img = PILImage.open(img_path)\n",
    "            img.thumbnail(thumb_size)\n",
    "            buf = io.BytesIO()\n",
    "            img.save(buf, format='PNG')\n",
    "            buf.seek(0)\n",
    "            img_data = buf.getvalue()\n",
    "\n",
    "            # Create image widget\n",
    "            img_widget = widgets.Image(\n",
    "                value=img_data,\n",
    "                format='png',\n",
    "                width=200,\n",
    "                height=200,\n",
    "                layout=widgets.Layout(\n",
    "                    margin='0px'\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Simple VBox container for image and checkbox\n",
    "            container = widgets.VBox([\n",
    "                img_widget,\n",
    "                cb\n",
    "            ], layout=widgets.Layout(\n",
    "                border='1px solid #ddd',\n",
    "                margin='5px',\n",
    "                padding='5px',\n",
    "                align_items='center'\n",
    "            ))\n",
    "\n",
    "            image_checkboxes.append(container)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {str(e)}\")\n",
    "            # Create an error placeholder with checkbox\n",
    "            error_widget = widgets.HTML(\n",
    "                value=f\"‚ö†Ô∏è Error loading:<br>{os.path.basename(img_path)}\",\n",
    "                layout=widgets.Layout(\n",
    "                    height='200px',\n",
    "                    width='200px',\n",
    "                    display='flex',\n",
    "                    align_items='center',\n",
    "                    justify_content='center'\n",
    "                )\n",
    "            )\n",
    "\n",
    "            cb = widgets.Checkbox(\n",
    "                description=f\"{os.path.basename(img_path)}\",\n",
    "                indent=False,\n",
    "                layout=widgets.Layout(width='auto')\n",
    "            )\n",
    "            cb.image_path = img_path\n",
    "            current_batch_cbs.append(cb)\n",
    "\n",
    "            container = widgets.VBox([\n",
    "                error_widget,\n",
    "                cb\n",
    "            ], layout=widgets.Layout(\n",
    "                border='1px solid #ddd',\n",
    "                margin='5px',\n",
    "                padding='5px',\n",
    "                align_items='center'\n",
    "            ))\n",
    "\n",
    "            image_checkboxes.append(container)\n",
    "\n",
    "    # Store the checkboxes for this batch\n",
    "    output.current_batch_checkboxes = current_batch_cbs\n",
    "\n",
    "    # Rest of your show_batch function remains the same...\n",
    "    # Create grid layout\n",
    "    grid = []\n",
    "    for i in range(0, len(image_checkboxes), grid_cols):\n",
    "        row = image_checkboxes[i:i+grid_cols]\n",
    "        grid.append(widgets.HBox(row))\n",
    "\n",
    "    # Add instructions for the user\n",
    "    instructions = widgets.HTML(\n",
    "        value=\"\"\"\n",
    "        <div style=\"padding: 10px; background-color: #e3f2fd; border-radius: 5px; margin-bottom: 15px;\">\n",
    "            <p><strong>Instructions:</strong> Review the images and select the checkbox below each image you want to delete.\n",
    "            Click \"Delete Selected\" to mark them for deletion and move to the next batch. \n",
    "            When finished, click \"Confirm Deletion\" to permanently delete all marked images.</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    with output:\n",
    "        display(instructions)\n",
    "\n",
    "        # Display the grid\n",
    "        for row in grid:\n",
    "            display(row)\n",
    "\n",
    "        # Display buttons\n",
    "        button_box = widgets.HBox([next_button, delete_button, confirm_delete])\n",
    "        display(button_box)\n",
    "        display(status)\n",
    "\n",
    "\n",
    "def on_next_click(_):\n",
    "    index[\"i\"] += batch_size\n",
    "    show_batch()\n",
    "\n",
    "\n",
    "def on_delete_click(_):\n",
    "    # We need to track selected checkboxes differently since the widgets are cleared\n",
    "    # Let's modify show_batch to store the current batch checkboxes\n",
    "    if hasattr(output, 'current_batch_checkboxes'):\n",
    "        selected = [\n",
    "            cb.image_path for cb in output.current_batch_checkboxes if cb.value]\n",
    "        delete_list.extend(selected)\n",
    "        status.value = f\"üóëÔ∏è Marked {len(selected)} new image(s), {len(delete_list)} total for deletion.\"\n",
    "\n",
    "    # Move to next batch\n",
    "    index[\"i\"] += batch_size\n",
    "    show_batch()\n",
    "\n",
    "\n",
    "def delete_images(_):\n",
    "    if not delete_list:\n",
    "        status.value = \"No images selected for deletion.\"\n",
    "        return\n",
    "\n",
    "    deleted = 0\n",
    "    failed = 0\n",
    "\n",
    "    for path in delete_list:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "            deleted += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {path}: {e}\")\n",
    "            failed += 1\n",
    "\n",
    "    status.value = f\"‚úÖ Successfully deleted {deleted} images. {failed} failed.\"\n",
    "    delete_list.clear()\n",
    "\n",
    "    # Refresh the image list\n",
    "    image_paths.clear()\n",
    "    for root, _, files in os.walk(image_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(image_extensions):\n",
    "                full_path = os.path.join(root, file)\n",
    "                if os.path.isfile(full_path):\n",
    "                    image_paths.append(full_path)\n",
    "\n",
    "    index[\"i\"] = 0\n",
    "    show_batch()\n",
    "\n",
    "\n",
    "next_button.on_click(on_next_click)\n",
    "delete_button.on_click(on_delete_click)\n",
    "confirm_delete.on_click(delete_images)\n",
    "\n",
    "display(output)\n",
    "show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for dataset generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJpoRpAsEnD6"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "def verify_or_create_dir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "results_path = workdir + \"DS_res/\"\n",
    "\n",
    "# Get all subfolders inside results_path\n",
    "path_to_classes = [f.path for f in os.scandir(\n",
    "    results_path) if f.is_dir() and \"bbs\" not in f.name]\n",
    "\n",
    "# Build list of (path, class_name) tuples\n",
    "fg_folders = [(path, os.path.basename(path)) for path in path_to_classes]\n",
    "\n",
    "# Define folders\n",
    "bg_folder = workdir + \"bg/\"\n",
    "verify_or_create_dir(bg_folder)\n",
    "output_folder = workdir + \"dsyolo_test_jul5_1/\"\n",
    "objects_list = [os.path.basename(class_path) for class_path in path_to_classes]\n",
    "\n",
    "# If you have a list of original classes, uncomment and fill it\n",
    "original_classes = [\n",
    "    #     \"exampleClass1\", \"exampleClass2\", \"exampleClass3\", \"exampleClass4\",\n",
    "]\n",
    "\n",
    "# Add new classes at the end only\n",
    "all_detected_classes = [os.path.basename(\n",
    "    class_path) for class_path in path_to_classes]\n",
    "\n",
    "# Append only the new classes\n",
    "final_classes = original_classes.copy()\n",
    "for cls in all_detected_classes:\n",
    "    if cls not in final_classes:\n",
    "        final_classes.append(cls)\n",
    "\n",
    "# Create annotations_ID and categories using final_classes\n",
    "annotations_ID = {cls: i for i, cls in enumerate(final_classes)}\n",
    "categories = [{\"id\": i, \"name\": cls} for i, cls in enumerate(final_classes)]\n",
    "\n",
    "print(\"annotations_ID:\", annotations_ID)\n",
    "print(\"categories:\", categories)\n",
    "\n",
    "# Load the list of files in each of the folders\n",
    "fg_files = {}\n",
    "for folder, category in fg_folders:\n",
    "    fg_files[category] = os.listdir(folder)\n",
    "\n",
    "# Define the folder structure\n",
    "subfolders = [\n",
    "    \"train/images\",\n",
    "    \"train/labels\",\n",
    "    \"test/images\",\n",
    "    \"test/labels\",\n",
    "    \"valid/images\",\n",
    "    \"valid/labels\",\n",
    "]\n",
    "\n",
    "# Create them\n",
    "for sub in subfolders:\n",
    "    verify_or_create_dir(os.path.join(output_folder, sub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBOYwQpeLijp"
   },
   "source": [
    "## Get backgrounds\n",
    "\n",
    "For this step, add background images to ./bg\n",
    "\n",
    "You can run the next cell to download and format a default dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzHBMsQ0R6b0",
    "outputId": "5e1afbb7-1c68-42ce-e97a-b4778adc9cb8"
   },
   "outputs": [],
   "source": [
    "!pip install kagglehub\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "dataset_path = kagglehub.dataset_download(\"balraj98/stanford-background-dataset\")\n",
    "os.system(f'cp \"{dataset_path}/images/\"* {workdir}bg/')\n",
    "\n",
    "dataset_path = kagglehub.dataset_download(\"adikurniawan/color-dataset-for-color-recognition\")\n",
    "os.system(f'find \"{dataset_path}/training_dataset/\" -type f -exec cp {{}} {workdir}bg/ \\;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove corrupt images\n",
    "\n",
    "You con also remove a percentage of images by modifying _delete_percentage_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyD-Xx4qXLfY",
    "outputId": "8285801f-1437-4df1-d572-4ef6eac4dcd8"
   },
   "outputs": [],
   "source": [
    "delete_percentage = 0  # e.g., 0.1 for 10%\n",
    "debug = False  # Set to True to print deleted files\n",
    "min_width = 0  # Minimum width\n",
    "min_height = 0  # Minimum height\n",
    "\n",
    "\n",
    "def clean_and_trim_dataset(folder):\n",
    "    total_removed = 0\n",
    "    low_res_removed = 0\n",
    "    valid_images = []\n",
    "\n",
    "    # Step 1: Remove corrupt images and low resolution ones\n",
    "    for img_name in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "        if not os.path.isfile(img_path):\n",
    "            continue\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img.verify()\n",
    "\n",
    "            with Image.open(img_path) as img:  # reopen to get size\n",
    "                width, height = img.size\n",
    "                if width < min_width or height < min_height:\n",
    "                    if debug:\n",
    "                        print(\n",
    "                            f\"Deleting low resolution image: {img_path} ({width}x{height})\")\n",
    "                    os.remove(img_path)\n",
    "                    low_res_removed += 1\n",
    "                else:\n",
    "                    valid_images.append(img_path)\n",
    "\n",
    "        except (UnidentifiedImageError, OSError):\n",
    "            if debug:\n",
    "                print(f\"Deleting corrupt image: {img_path}\")\n",
    "            os.remove(img_path)\n",
    "            total_removed += 1\n",
    "\n",
    "    print(f\"Removed {total_removed} corrupt images\")\n",
    "    print(f\"Removed {low_res_removed} low resolution images\")\n",
    "\n",
    "    # Step 2: Remove a percentage of the valid images\n",
    "    to_delete_count = int(len(valid_images) * delete_percentage)\n",
    "    to_delete = random.sample(valid_images, to_delete_count)\n",
    "    for img_path in to_delete:\n",
    "        if debug:\n",
    "            print(f\"Deleting random image for dataset reduction: {img_path}\")\n",
    "        os.remove(img_path)\n",
    "\n",
    "    print(f\"Removed {len(to_delete)} images to reduce dataset size\")\n",
    "\n",
    "\n",
    "def count_files_in_dir(directory):\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(\n",
    "        os.path.join(directory, f))]\n",
    "    return len(files)\n",
    "\n",
    "\n",
    "# Apply on /content/bg\n",
    "clean_and_trim_dataset(workdir + \"bg\")\n",
    "\n",
    "# Count remaining images\n",
    "print(f\"Remaining number of images: {count_files_in_dir(workdir + 'bg')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize bg images\n",
    "\n",
    "Backgrounds don't have to be the best quality, even when scaled up, but they're the canvas for pasting the object images so a good resolution will improve the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "base_path = workdir + \"bg\"\n",
    "size = 640\n",
    "for filename in os.listdir(base_path):\n",
    "    file_path = os.path.join(base_path, filename)\n",
    "    # if not a file, skip\n",
    "    if not os.path.isfile(file_path):\n",
    "        continue\n",
    "    try:\n",
    "        with Image.open(file_path) as img:\n",
    "            img = img.resize((size, size))\n",
    "            img.save(file_path)\n",
    "    except (UnidentifiedImageError, OSError) as e:\n",
    "        print(f\"Removing corrupt file: {file_path}\")\n",
    "        os.remove(file_path)  # delete corrupt image\n",
    "\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWV-quChdy0O"
   },
   "source": [
    "## Image generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "This cell handles the augmentation of the images, you can modify the parameters to your liking, but the defaults should be good enough for most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageDraw, ExifTags, ImageFilter\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import tqdm\n",
    "import cv2\n",
    "import math\n",
    "import argparse\n",
    "import sys\n",
    "from numba import njit, prange\n",
    "import numba\n",
    "\n",
    "\n",
    "# Constants for augmentations\n",
    "ZOOM_FACTOR = 1.2  # Maximum zoom factor\n",
    "BRIGHTNESS_FACTOR = 0.3  # Brightness adjustment range (0.5 to 1.5)\n",
    "CONTRAST_FACTOR = 0.2  # Contrast adjustment range (0.5 to 1.5)\n",
    "SATURATION_FACTOR = 0.3  # Saturation adjustment range (0.5 to 1.5)\n",
    "HUE_FACTOR = 0.05  # Hue adjustment range (-0.5 to 0.5)\n",
    "BLUR_FACTOR = 0.25  # Max Blur adjustment range (0 to blur_factor)\n",
    "NOISE_PROBABILITY = 0.5  # Probability of adding noise\n",
    "NOISE_FACTOR = 0.15  # Noise adjustment range (0 to noise_factor)\n",
    "BLOB_COUNT_MIN = 0  # Minimum number of blobs to add\n",
    "BLOB_COUNT_MAX = 2  # Maximum number of blobs to add\n",
    "BLOB_SIZE = (15, 150)  # Size range of blobs (min, max)\n",
    "BLOB_PROBABILITY = 0.15  # Probability of adding a blob\n",
    "QUALITY_FACTOR = 0.25 # Min quality that can be applied to the image compression e.g. 0.25 means image can be compressed to 25% of its original quality \n",
    "\n",
    "MULTIPLIER = 5\n",
    "\n",
    "def augment_image(image):\n",
    "    \n",
    "    def adjust_brightness(image):\n",
    "        enhancer = ImageEnhance.Brightness(image)\n",
    "        factor = random.uniform(1 - BRIGHTNESS_FACTOR, 1 + BRIGHTNESS_FACTOR)\n",
    "        return enhancer.enhance(factor)\n",
    "\n",
    "    def adjust_contrast(image):\n",
    "        enhancer = ImageEnhance.Contrast(image)\n",
    "        factor = random.uniform(1 - CONTRAST_FACTOR, 1 + CONTRAST_FACTOR)\n",
    "        return enhancer.enhance(factor)\n",
    "\n",
    "    def adjust_saturation(image):\n",
    "        enhancer = ImageEnhance.Color(image)\n",
    "        factor = random.uniform(1 - SATURATION_FACTOR, 1 + SATURATION_FACTOR)\n",
    "        return enhancer.enhance(factor)\n",
    "\n",
    "    def adjust_hue(image):\n",
    "        enhancer = ImageEnhance.Color(image)\n",
    "        factor = random.uniform(1 - HUE_FACTOR, 1 + HUE_FACTOR)\n",
    "        # Convert to HSV, adjust hue, and convert back to RGB\n",
    "        hsv_image = image.convert('HSV')\n",
    "        h, s, v = hsv_image.split()\n",
    "        h = h.point(lambda p: (p + int(factor * 255)) % 256)\n",
    "        hsv_image = Image.merge('HSV', (h, s, v))\n",
    "        return hsv_image.convert('RGB')\n",
    "\n",
    "    def add_blur(image):\n",
    "        blur_factor = random.uniform(0, BLUR_FACTOR)\n",
    "        if blur_factor > 0:\n",
    "            return image.filter(ImageFilter.GaussianBlur(radius=blur_factor))\n",
    "        return image\n",
    "\n",
    "    def add_noise(image):\n",
    "        noise_factor = random.uniform(0, NOISE_FACTOR)\n",
    "        if not random.random() < NOISE_PROBABILITY:\n",
    "            return image\n",
    "        if noise_factor > 0:\n",
    "            img_arr = np.array(image, dtype=np.float32)\n",
    "            if img_arr.shape[2] == 4:\n",
    "                # Only add noise to RGB channels, keep alpha unchanged\n",
    "                noise = np.random.normal(0, noise_factor, [img_arr.shape[0], img_arr.shape[1], 3])\n",
    "                noise = (noise * 255).astype(np.float32)\n",
    "                img_arr[:, :, :3] = np.clip(img_arr[:, :, :3] + noise, 0, 255)\n",
    "                noisy_image = img_arr.astype(np.uint8)\n",
    "            else:\n",
    "                noise = np.random.normal(0, noise_factor, [img_arr.shape[0], img_arr.shape[1], 3])\n",
    "                noise = (noise * 255).astype(np.float32)\n",
    "                img_arr = np.clip(img_arr + noise, 0, 255)\n",
    "                noisy_image = img_arr.astype(np.uint8)\n",
    "                return Image.fromarray(noisy_image, mode=image.mode)\n",
    "        return image\n",
    "\n",
    "    def generate_blob_points(center_x, center_y, radius, irregularity=0.5, spikiness=0.5, num_points=12):\n",
    "        \"\"\"\n",
    "        Generate a blob-like shape using a star/polygon algorithm with randomness.\n",
    "        \"\"\"\n",
    "        \n",
    "        points = []\n",
    "        angle_step = 2 * math.pi / num_points\n",
    "\n",
    "        for i in range(num_points):\n",
    "            angle = i * angle_step\n",
    "            # Vary radius for spikiness\n",
    "            rand_radius = radius * (1 + random.uniform(-spikiness, spikiness))\n",
    "            # Add offset for irregularity\n",
    "            offset_angle = angle + random.uniform(-irregularity, irregularity) * angle_step\n",
    "            x = center_x + rand_radius * math.cos(offset_angle)\n",
    "            y = center_y + rand_radius * math.sin(offset_angle)\n",
    "            points.append((x, y))\n",
    "\n",
    "        return points\n",
    "\n",
    "    def add_blobs(image):\n",
    "        if random.random() > BLOB_PROBABILITY:\n",
    "            return image\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        blob_count = random.randint(BLOB_COUNT_MIN, BLOB_COUNT_MAX)\n",
    "\n",
    "        for _ in range(blob_count):\n",
    "            x = random.randint(0, image.width)\n",
    "            y = random.randint(0, image.height)\n",
    "            size = random.randint(*BLOB_SIZE)\n",
    "            color = (\n",
    "                random.randint(0, 255),\n",
    "                random.randint(0, 255),\n",
    "                random.randint(0, 255),\n",
    "                random.randint(100, 255)  # Optional alpha\n",
    "            )\n",
    "            blob_points = generate_blob_points(x, y, size, irregularity=0.4, spikiness=0.6, num_points=random.randint(8, 16))\n",
    "            draw.polygon(blob_points, fill=color)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def alter_quality(image):\n",
    "        quality_ratio = random.uniform(QUALITY_FACTOR, 1)\n",
    "        frame = np.array(image)\n",
    "        result, encoded = cv2.imencode('.jpg', frame, [int(cv2.IMWRITE_JPEG_QUALITY), int(quality_ratio * 100)])\n",
    "        return Image.fromarray(cv2.imdecode(encoded, cv2.IMREAD_COLOR))\n",
    "\n",
    "    # Apply augmentations\n",
    "    augmentations = [adjust_brightness, adjust_contrast, adjust_saturation, add_blobs, \n",
    "                    adjust_hue, add_blur, add_noise, alter_quality]\n",
    "    random.shuffle(augmentations)\n",
    "    \n",
    "    for aug in augmentations:\n",
    "        image = aug(image)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset\n",
    "This cell takes the segmented images of the classes and backgrounds and generate images with a random amount of objects in them scattered around.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DjdUzK7Lk9T"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image, ImageDraw, ImageEnhance, ImageFilter, ImageFont, UnidentifiedImageError\n",
    "import numpy as np\n",
    "import yaml\n",
    "import tqdm\n",
    "\n",
    "images = []\n",
    "annotations = []\n",
    "annotations2 = []\n",
    "annot_csv = []\n",
    "\n",
    "img_id = int(0)\n",
    "anno_id = int(0)\n",
    "\n",
    "min_size_ratio = 0.05  # Objects must be at least 10% of bg size\n",
    "max_size_ratio = 0.35  # Objects can be at most 75% of bg size\n",
    "\n",
    "# Define the maximum overlap as a percentage\n",
    "max_overlap_pct = 25\n",
    "\n",
    "trainfolder = output_folder + \"train/\"\n",
    "validfolder = output_folder + \"valid/\"\n",
    "\n",
    "images_to_generate = 15000\n",
    "max_objects_per_image = 8\n",
    "\n",
    "progress_bar = tqdm.tqdm(total=images_to_generate, desc=\"Generating images\")\n",
    "\n",
    "for j in range(images_to_generate):\n",
    "    with open(f'{trainfolder}labels/{img_id}.txt', 'w') as file:\n",
    "        pass\n",
    "\n",
    "    # Decide if this image should be empty\n",
    "    if random.random() < 0.10:  # 10% chance\n",
    "        num_objects = 0\n",
    "    else:\n",
    "        num_objects = random.randint(1, max_objects_per_image)\n",
    "\n",
    "    fg_categories = random.choices(objects_list, k=num_objects)\n",
    "\n",
    "    fg_files_selected = [[category, random.choice(\n",
    "        fg_files[category])] for category in fg_categories]\n",
    "\n",
    "    fg_imgs = []\n",
    "    for img in fg_files_selected:\n",
    "        folder = [f[0] for f in fg_folders if f[1] == img[0]][0]\n",
    "        fg_img = Image.open(folder + \"/\" + img[1]).convert(\"RGBA\")\n",
    "        fg_imgs.append(\n",
    "            [img[0], Image.open(folder + \"/\" + img[1]), folder + img[1]])\n",
    "\n",
    "    bg_files = os.listdir(bg_folder)\n",
    "    bg_file = random.choice(bg_files)\n",
    "    # ignore if bg_file is not a file\n",
    "    while not os.path.isfile(bg_folder + bg_file):\n",
    "        bg_file = random.choice(bg_files)\n",
    "    bg_img = Image.open(bg_folder + bg_file)\n",
    "    bg_img = bg_img.convert(\"RGBA\")\n",
    "\n",
    "    occupied_mask = np.zeros((bg_img.height, bg_img.width), dtype=np.uint8)\n",
    "\n",
    "    for img in fg_imgs:\n",
    "        fg_img = img[1]\n",
    "\n",
    "        angle = random.randint(-5, 5)\n",
    "        fg_img = fg_img.rotate(angle, resample=Image.BICUBIC, expand=True)\n",
    "\n",
    "        # Resize using dynamic scale bounds based on background\n",
    "        original_w, original_h = fg_img.size\n",
    "        max_scale_w = (bg_img.width * max_size_ratio) / original_w\n",
    "        max_scale_h = (bg_img.height * max_size_ratio) / original_h\n",
    "        min_scale_w = (bg_img.width * min_size_ratio) / original_w\n",
    "        min_scale_h = (bg_img.height * min_size_ratio) / original_h\n",
    "\n",
    "        scale_min = max(min_scale_w, min_scale_h)\n",
    "        scale_max = min(max_scale_w, max_scale_h)\n",
    "\n",
    "        # Clamp to [0.01, 1.0] just in case\n",
    "        scale_min = max(scale_min, 0.01)\n",
    "        scale_max = min(scale_max, 1.0)\n",
    "\n",
    "        # If bounds are inverted due to very large fg, clamp both to min_scale\n",
    "        if scale_max < scale_min:\n",
    "            scale_max = scale_min\n",
    "\n",
    "        scale = random.uniform(scale_min, scale_max)\n",
    "\n",
    "        new_w = int(original_w * scale)\n",
    "        new_h = int(original_h * scale)\n",
    "\n",
    "        fg_img = fg_img.resize((new_w, new_h), resample=Image.BICUBIC)\n",
    "\n",
    "        fg_img = ImageEnhance.Brightness(\n",
    "            fg_img).enhance(random.uniform(0.8, 1.2))\n",
    "        fg_img = ImageEnhance.Contrast(\n",
    "            fg_img).enhance(random.uniform(0.8, 1.2))\n",
    "        fg_img = ImageEnhance.Color(fg_img).enhance(random.uniform(0.8, 1.2))\n",
    "        fg_img = fg_img.filter(ImageFilter.GaussianBlur(\n",
    "            radius=random.uniform(0.0, 0.8)))\n",
    "\n",
    "        img[1] = fg_img\n",
    "\n",
    "        max_x = bg_img.width - fg_img.width\n",
    "        max_y = bg_img.height - fg_img.height\n",
    "\n",
    "        for attempt in range(50):\n",
    "            x = random.randint(0, max_x)\n",
    "            y = random.randint(0, max_y)\n",
    "\n",
    "            fg_mask = np.array(fg_img.split()[-1]) > 0\n",
    "\n",
    "            # Make sure dimensions align (especially after rotation/resize)\n",
    "            mask_h, mask_w = fg_mask.shape\n",
    "            if y + mask_h > occupied_mask.shape[0] or x + mask_w > occupied_mask.shape[1]:\n",
    "                continue  # skip if out of bounds (shouldn‚Äôt usually happen)\n",
    "\n",
    "            occ_crop = occupied_mask[y:y + mask_h, x:x + mask_w]\n",
    "            fg_mask_area = np.sum(fg_mask)\n",
    "            occ_crop_area = np.sum(occ_crop)\n",
    "            overlap = np.sum(np.logical_and(fg_mask, occ_crop))\n",
    "\n",
    "            allowed_overlap_fg = max_overlap_pct / 100 * fg_mask_area\n",
    "            allowed_overlap_occ = max_overlap_pct / 100 * \\\n",
    "                occ_crop_area if occ_crop_area > 0 else 0\n",
    "\n",
    "            # Accept placement only if it doesn't cover too much of either\n",
    "            if overlap <= allowed_overlap_fg and overlap <= allowed_overlap_occ:\n",
    "                occupied_mask[y:y + fg_img.height, x:x +\n",
    "                              fg_img.width] = np.logical_or(occ_crop, fg_mask)\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        seg_img = fg_img\n",
    "        img_arr = np.array(seg_img)\n",
    "        mask = img_arr[:, :, 3] != 0\n",
    "\n",
    "        segmentation = []\n",
    "        for i in range(mask.shape[0]):\n",
    "            for j in range(mask.shape[1]):\n",
    "                if mask[i, j]:\n",
    "                    segmentation.append(j + x)\n",
    "                    segmentation.append(i + y)\n",
    "        segmentation = [segmentation]\n",
    "\n",
    "        area = abs(sum(\n",
    "            segmentation[0][2 * i] * segmentation[0][(2 * i + 3) % len(segmentation[0])] -\n",
    "            segmentation[0][(2 * i + 2) % len(segmentation[0])\n",
    "                            ] * segmentation[0][2 * i + 1]\n",
    "            for i in range(len(segmentation[0]) // 2)\n",
    "        )) / 2\n",
    "\n",
    "        bg_img.paste(fg_img, (x, y), fg_img)\n",
    "\n",
    "        x1, y1 = x, y\n",
    "        x2 = x + fg_img.width\n",
    "        y2 = y + fg_img.height\n",
    "\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "\n",
    "        x_center_ann = ((x1 + x2) / 2) / bg_img.width\n",
    "        y_center_ann = ((y1 + y2) / 2) / bg_img.height\n",
    "        width_ann = (x2 - x1) / bg_img.width\n",
    "        height_ann = (y2 - y1) / bg_img.height\n",
    "\n",
    "        if not (0 <= x_center_ann <= 1 and 0 <= y_center_ann <= 1 and 0 <= width_ann <= 1 and 0 <= height_ann <= 1):\n",
    "            continue\n",
    "\n",
    "        # with open(f'{trainfolder}labels/{img_id}.txt', 'a') as f:\n",
    "        #     f.write(\n",
    "        #         f\"{annotations_ID[img[0]]} {x_center_ann} {y_center_ann} {width_ann} {height_ann}\\n\")\n",
    "\n",
    "        # Create segmentation labels\n",
    "        normalize_seg = []\n",
    "        for i in range(len(segmentation[0])):\n",
    "            if i % 2 == 0:\n",
    "                val = segmentation[0][i] / bg_img.width\n",
    "            else:\n",
    "                val = segmentation[0][i] / bg_img.height\n",
    "            normalize_seg.append(str(val))\n",
    "        with open(f'{trainfolder}labels/{img_id}.txt', 'a') as f:\n",
    "            f.write(f\"{annotations_ID[img[0]]} {' '.join(normalize_seg)}\\n\")\n",
    "\n",
    "        annotations2.append({\n",
    "            \"id\": anno_id, \"image_id\": img_id, \"category_id\": annotations_ID[img[0]],\n",
    "            \"bbox\": [x, y, fg_img.width, fg_img.height],\n",
    "            \"segmentation\": segmentation, \"area\": area, \"iscrowd\": 0\n",
    "        })\n",
    "        annotations.append({\n",
    "            \"id\": anno_id, \"image_id\": img_id, \"category_id\": annotations_ID[img[0]],\n",
    "            \"bbox\": [x, y, fg_img.width, fg_img.height],\n",
    "            \"segmentation\": [], \"area\": fg_img.height * fg_img.width, \"iscrowd\": 0\n",
    "        })\n",
    "        annot_csv.append([\n",
    "            \"TRAIN\", output_folder +\n",
    "            str(img_id)+\".jpg\", img[0], x/bg_img.width, y/bg_img.height,\n",
    "            \"\", \"\", (x+fg_img.width) /\n",
    "            bg_img.width, (y+fg_img.height)/bg_img.height\n",
    "        ])\n",
    "\n",
    "        anno_id += 1\n",
    "\n",
    "    \n",
    "    # Apply additional augmentation\n",
    "    bg_img = augment_image(bg_img)\n",
    "    \n",
    "    bg_img = bg_img.convert(\"RGB\")\n",
    "    bg_img.save(f\"{trainfolder}images/\" + str(img_id) + \".jpg\", quality=100)\n",
    "    images.append({\"id\": img_id, \"file_name\": str(img_id) + \".jpg\",\n",
    "                  \"height\": bg_img.height, \"width\": bg_img.width})\n",
    "    img_id += 1\n",
    "    \n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Create data.yaml\n",
    "data = dict(\n",
    "    train=f\"{trainfolder}images\",\n",
    "    val=f\"{validfolder}images\",\n",
    "    test=f\"{validfolder}images\",\n",
    "    nc=len(annotations_ID),\n",
    "    names=list(annotations_ID.keys())\n",
    ")\n",
    "\n",
    "with open(f'{output_folder}data.yaml', 'w') as outfile:\n",
    "    yaml.dump(data, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check generated images\n",
    "\n",
    "This cell shows n random images from the dataset and draws the bounding boxes from the labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zHVZeOCzUE3x",
    "outputId": "524e3fbb-522f-4c13-ac8e-f2fa9dbcf8cd"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display, Javascript, clear_output\n",
    "import ipywidgets as widgets\n",
    "import random\n",
    "# from PIL import Image, ImageDraw, ImageEnhance, ImageFilter, ImageFont, UnidentifiedImageError\n",
    "from PIL import ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# === CONFIG ===\n",
    "images_dir = workdir + \"dsyolo_test_jul5_1/train/images\"\n",
    "labels_dir = workdir + \"dsyolo_test_jul5_1/train/labels\"\n",
    "num_samples = 15\n",
    "# workdir=\"/content/\"\n",
    "# Get all image files\n",
    "image_files = [f for f in os.listdir(\n",
    "    images_dir) if f.endswith(('.jpg', '.png'))]\n",
    "sampled_files = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "\n",
    "for image_file in sampled_files:\n",
    "    image_path = os.path.join(images_dir, image_file)\n",
    "    label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
    "    label_path = os.path.join(labels_dir, label_file)\n",
    "\n",
    "    # Load image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    img_width, img_height = image.size\n",
    "\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = f.readlines()\n",
    "\n",
    "        for label in labels:\n",
    "            cls, x_center, y_center, w, h = map(float, label.strip().split())\n",
    "            x_center *= img_width\n",
    "            y_center *= img_height\n",
    "            w *= img_width\n",
    "            h *= img_height\n",
    "            x0 = x_center - w / 2\n",
    "            y0 = y_center - h / 2\n",
    "            x1 = x_center + w / 2\n",
    "            y1 = y_center + h / 2\n",
    "            draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=5)\n",
    "            draw.text((x0, y0), str(int(cls)), fill=\"red\")\n",
    "\n",
    "    # Show image with bounding boxes\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.title(image_file)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMY4iC9HM6Mm"
   },
   "source": [
    "## Split images\n",
    "\n",
    "Take a percentage of the images and move them to test and validation directories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vczfmj5OM7Rl",
    "outputId": "4f13faa6-832b-46ee-b0dd-6debca34dc9e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "validation = 0.1\n",
    "test = 0.1\n",
    "\n",
    "# Assumes test has 100% of data\n",
    "output_folder = workdir + \"/dsyolo_test_jul5_1/\"\n",
    "trainfolder = output_folder + \"train/\"\n",
    "trainfolderimgs = trainfolder + \"images/\"\n",
    "trainfolderlabels = trainfolder + \"labels/\"\n",
    "testfolder = output_folder + \"test/\"\n",
    "testfolderimgs = testfolder + \"images/\"\n",
    "testfolderlabels = testfolder + \"labels/\"\n",
    "validfolder = output_folder + \"valid/\"\n",
    "validfolderimgs = validfolder + \"images/\"\n",
    "validfolderlabels = validfolder + \"labels/\"\n",
    "\n",
    "fullSize = len(os.listdir(trainfolderimgs))\n",
    "validSize = int(fullSize * validation)\n",
    "testSize = int(fullSize * test)\n",
    "\n",
    "for i in range(validSize):\n",
    "    filelist = os.listdir(trainfolderimgs)\n",
    "    # randomize file list, to not pick files in order\n",
    "    random.shuffle(filelist)\n",
    "    filetomove = filelist[i]\n",
    "    # take out .jpg, .png, etc\n",
    "    filetomovename = filetomove[:-4]\n",
    "    # move images\n",
    "    shutil.move(f\"{trainfolderimgs}{filetomove}\",\n",
    "                f\"{validfolderimgs}{filetomove}\")\n",
    "    # move labels\n",
    "    shutil.move(f\"{trainfolderlabels}{filetomovename}.txt\",\n",
    "                f\"{validfolderlabels}{filetomovename}.txt\")\n",
    "for i in range(testSize):\n",
    "    filetomove = os.listdir(trainfolderimgs)[i]\n",
    "    # take out .jpg, .png, etc\n",
    "    filetomovename = filetomove[:-4]\n",
    "    # move images\n",
    "    shutil.move(f\"{trainfolderimgs}{filetomove}\",\n",
    "                f\"{testfolderimgs}{filetomove}\")\n",
    "    # move labels\n",
    "    shutil.move(f\"{trainfolderlabels}{filetomovename}.txt\",\n",
    "                f\"{testfolderlabels}{filetomovename}.txt\")\n",
    "\n",
    "# Validation\n",
    "print(f\"Train size is now: {len(os.listdir(trainfolderimgs))}\")\n",
    "print(f\"Validation size is now: {len(os.listdir(validfolderimgs))}\")\n",
    "print(f\"Test size is now: {len(os.listdir(testfolderimgs))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGyMZpYMEjiq"
   },
   "source": [
    "## Train a yolo model with the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gQ767sidy0P"
   },
   "source": [
    "Clean invalid labels and then train yolo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gOyra8VE0-0",
    "outputId": "1a9071d3-5685-4bb5-c6e9-6f5d2faea637"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\" # for some systems\n",
    "from ultralytics import YOLO\n",
    "\n",
    "os.chdir(workdir)\n",
    "\n",
    "# Load a YOLOv8 model (you can also use 'yolov8n.yaml', 'yolov8s.yaml', etc.)\n",
    "model = YOLO(\"yolo11m.yaml\")  # \"yolo11m.yaml\"\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=workdir + \"ds_final/data.yaml\",\n",
    "    epochs=200,  # change to 200\n",
    "    imgsz=640,\n",
    "    batch=64,  # 32, 64, 128 or -1\n",
    "    # degrees=15,\n",
    "    # translate=0.1,\n",
    "    # shear=5,\n",
    "    # scale=0.5,\n",
    "    # perspective=0.001,\n",
    "    # flipud=0.3,\n",
    "    # fliplr=0.5,\n",
    "    # mosaic=1.0,\n",
    "    # mixup=0.2,\n",
    "    # copy_paste=0.1\n",
    "    patience=25,\n",
    "    save_period=10,\n",
    "    cache=True,\n",
    "    amp=True,\n",
    "    device=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TY83CIQaFcPO",
    "outputId": "9aeee6c6-44aa-494d-f0bc-0cf4054fc95d"
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "os.chdir(workdir)\n",
    "\n",
    "# Load the best trained model\n",
    "model = YOLO(workdir + \"runs/detect/train/weights/best.pt\")\n",
    "\n",
    "# Run inference on test images\n",
    "results = model.predict(source=workdir + \"test\", save=True, conf=0.5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sam3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0674519ce3f94cb2af1795284ac5c254": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "074ac668b1874d7898bb48eb8c1e5609": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07aa5b72d67a4406a36158ac73052965": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10cc1d0e80a64ae9a74e26cf271d4e3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a31bb492ac14114a4834ce01606c215",
       "IPY_MODEL_d17bbb777f684b2ab3218437fa3addac",
       "IPY_MODEL_5040ef2b0be949f29b9bb14501766d8c"
      ],
      "layout": "IPY_MODEL_9a6dd1b69c534089ae76de0c7066f536"
     }
    },
    "1b3e6578daa14e878fa81b49be27a1c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21e1b46e14754b2c89fd9fb3e02447ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c023625bc6646918480dd004b28d9d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_afa32ee98b66461bb78372e6d7a1cc3e",
       "IPY_MODEL_3ea1c1a5199f4d18a23984669bd64f70",
       "IPY_MODEL_673756d1faf649ce8a73542506330efa"
      ],
      "layout": "IPY_MODEL_d4a4280d6bad475eb85ce1c34bdc8b4b"
     }
    },
    "2e7c6e1d2ce540a0947bd23a4eefaeb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32dd7428aaca4873b1372fc3d53d86f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c63dd84d492454a9db035417904badf",
       "IPY_MODEL_57b147ec95bd4a5281182a5593cede2d",
       "IPY_MODEL_e0a1d9fc6acb4c48b673af883342ca14"
      ],
      "layout": "IPY_MODEL_a4e0fbc727a74f99899ed75b38ddf475"
     }
    },
    "32e982541d2d4a42b8ec741069277148": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39ed14f4c1744d47ab5a6501d7ceb066": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cc6e765638b4c8693ad1939adbc7075": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0674519ce3f94cb2af1795284ac5c254",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f5befeb518141d78d8ab648b7aac290",
      "value": 440449768
     }
    },
    "3dc907d3dd9d46f4a0a6602cfdbcb5c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ea1c1a5199f4d18a23984669bd64f70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a843a7504f59438498c3d387300258c0",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_32e982541d2d4a42b8ec741069277148",
      "value": 466062
     }
    },
    "478de8615e99440bb8c2c46abc682138": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_590eff2c9bf94a408824b5ab424b1d86",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c319048ba704dc8999f93ac2e3983c0",
      "value": 48
     }
    },
    "4f5befeb518141d78d8ab648b7aac290": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5040ef2b0be949f29b9bb14501766d8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc6a084b27bf43199133a983c0e998d9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8240eac68b4e486fabfb7bc0e6ede318",
      "value": "‚Äá232k/232k‚Äá[00:00&lt;00:00,‚Äá1.21MB/s]"
     }
    },
    "5049c90d37d54420b3dddc119adb99ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e7c6e1d2ce540a0947bd23a4eefaeb5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a9b569e9cfbc427899642a4d04a40511",
      "value": "‚Äá48.0/48.0‚Äá[00:00&lt;00:00,‚Äá4.19kB/s]"
     }
    },
    "57b147ec95bd4a5281182a5593cede2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d7f44fe4a3e42fba2d7f366b2cbdb35",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_715dcfb65f2847bba07cd70e87fef753",
      "value": 570
     }
    },
    "590eff2c9bf94a408824b5ab424b1d86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a31bb492ac14114a4834ce01606c215": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bdf7fc5abe5c4f66a43087c6983d7a08",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_62d815b28d6c44f6a7929937e1d946da",
      "value": "vocab.txt:‚Äá100%"
     }
    },
    "6199d41041f84bd88b19c542d91b737b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62d815b28d6c44f6a7929937e1d946da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65b1f7e1f7574badb642231988b7971f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df27dfcd46794ebba579ccdc5d917356",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1b3e6578daa14e878fa81b49be27a1c9",
      "value": "‚Äá440M/440M‚Äá[00:01&lt;00:00,‚Äá313MB/s]"
     }
    },
    "66502c3a78ba4d7493c596643756f984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "673756d1faf649ce8a73542506330efa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_758b5e025dd64b5eaaad54d6bde5b1a8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_3dc907d3dd9d46f4a0a6602cfdbcb5c5",
      "value": "‚Äá466k/466k‚Äá[00:00&lt;00:00,‚Äá2.39MB/s]"
     }
    },
    "6c319048ba704dc8999f93ac2e3983c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "715dcfb65f2847bba07cd70e87fef753": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "758b5e025dd64b5eaaad54d6bde5b1a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8240eac68b4e486fabfb7bc0e6ede318": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8afcd9a2728e49249d131455ca90b387": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe65928650c441ff9f7862bb9f0252ca",
       "IPY_MODEL_3cc6e765638b4c8693ad1939adbc7075",
       "IPY_MODEL_65b1f7e1f7574badb642231988b7971f"
      ],
      "layout": "IPY_MODEL_21e1b46e14754b2c89fd9fb3e02447ef"
     }
    },
    "91c04aac570a4afba58c56556b073299": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9a6dd1b69c534089ae76de0c7066f536": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c63dd84d492454a9db035417904badf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2543c38f7a64a5896a0575aea4b9aea",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6199d41041f84bd88b19c542d91b737b",
      "value": "config.json:‚Äá100%"
     }
    },
    "9d7f44fe4a3e42fba2d7f366b2cbdb35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4bf668dc0144abf9612f84a6852a810": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4e0fbc727a74f99899ed75b38ddf475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a843a7504f59438498c3d387300258c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9b569e9cfbc427899642a4d04a40511": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac52a1e1fdc24daba3fa3e83c3bde187": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af9c10f0df6c4bc5a63ea9fc18fef6a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afa32ee98b66461bb78372e6d7a1cc3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39ed14f4c1744d47ab5a6501d7ceb066",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_db34ee159254442988370a564c2c22aa",
      "value": "tokenizer.json:‚Äá100%"
     }
    },
    "b1a4231b6ad34afa9d7730ed4a03b2d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc6a084b27bf43199133a983c0e998d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdf7fc5abe5c4f66a43087c6983d7a08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c05faa28b73b4af5942dcaa183aa0d23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1a4231b6ad34afa9d7730ed4a03b2d3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ef258e82c4f941f296c9628628a2aab9",
      "value": "tokenizer_config.json:‚Äá100%"
     }
    },
    "c2543c38f7a64a5896a0575aea4b9aea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d17bbb777f684b2ab3218437fa3addac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac52a1e1fdc24daba3fa3e83c3bde187",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_91c04aac570a4afba58c56556b073299",
      "value": 231508
     }
    },
    "d4a4280d6bad475eb85ce1c34bdc8b4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d69bb9ad91f648e29cc9dfff69e7728e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c05faa28b73b4af5942dcaa183aa0d23",
       "IPY_MODEL_478de8615e99440bb8c2c46abc682138",
       "IPY_MODEL_5049c90d37d54420b3dddc119adb99ba"
      ],
      "layout": "IPY_MODEL_af9c10f0df6c4bc5a63ea9fc18fef6a3"
     }
    },
    "db34ee159254442988370a564c2c22aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df27dfcd46794ebba579ccdc5d917356": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0a1d9fc6acb4c48b673af883342ca14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4bf668dc0144abf9612f84a6852a810",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_66502c3a78ba4d7493c596643756f984",
      "value": "‚Äá570/570‚Äá[00:00&lt;00:00,‚Äá55.0kB/s]"
     }
    },
    "ef258e82c4f941f296c9628628a2aab9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe65928650c441ff9f7862bb9f0252ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_074ac668b1874d7898bb48eb8c1e5609",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_07aa5b72d67a4406a36158ac73052965",
      "value": "model.safetensors:‚Äá100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
